"""
ì‹ ì œí’ˆ ì•„ì´ë””ì–´ ìƒì„± í˜ì´ì§€
"""
import streamlit as st
import pandas as pd
import re
from datetime import datetime
from collections import Counter
from pathlib import Path

from config import DB_PATH, PRODUCT_CATEGORIES, REVIVAL_POTENTIAL_LABELS
from database.db_manager import DatabaseManager

# ë¦¬í¬íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (2_ë¦¬ì„œì¹˜.pyì™€ ë™ì¼)
REPORTS_DIR = Path(__file__).parent.parent / "reports"

# AI ëª¨ë¸ ì„¤ì •
# Note: Sonnet 4.5, Haiku 4.5ëŠ” ì•„ì§ API ë¯¸ì§€ì› (ì›¹ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥)
AI_MODELS = {
    "Claude Opus 4.5 (ìµœê³  í’ˆì§ˆ)": {
        "provider": "anthropic",
        "id": "claude-opus-4-5-20251101",
        "cost": "~â‚©300ì›",
        "thinking_budget": 10000
    },
    "Claude Sonnet 4 (ê· í˜•)": {
        "provider": "anthropic",
        "id": "claude-sonnet-4-20250514",
        "cost": "~â‚©40ì›",
        "thinking_budget": 5000
    },
    "Claude Haiku 3.5 (ë¹ ë¦„)": {
        "provider": "anthropic",
        "id": "claude-3-5-haiku-20241022",
        "cost": "~â‚©3ì›",
        "thinking_budget": 0
    },
    "GPT-5.2 (OpenAI ìµœì‹ )": {
        "provider": "openai",
        "id": "gpt-5.2",
        "cost": "~â‚©50ì›"
    },
    "GPT-4o (ê· í˜•)": {
        "provider": "openai",
        "id": "gpt-4o",
        "cost": "~â‚©30ì›"
    }
}

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì¶œë ¥ í’ˆì§ˆ í–¥ìƒ)
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì˜¬ë¦¬ë¸Œì˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ë¥¼ ê¸°íší•˜ëŠ” **ì‹œë‹ˆì–´ í™”ì¥í’ˆ ì‹ ì œí’ˆ ê¸°íšì**ì…ë‹ˆë‹¤.

## ì—­í• 
- 10ë…„ ì´ìƒì˜ í™”ì¥í’ˆ ê¸°íš ê²½ë ¥
- ì˜¬ë¦¬ë¸Œì˜ íŠ¸ë Œë“œì™€ MZì„¸ëŒ€ ì†Œë¹„ íŒ¨í„´ì— ì •í†µ
- ì‹¤ì œ ì¶œì‹œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì œí’ˆ ì•„ì´ë””ì–´ ì œì•ˆ
- **ìµœì‹  ì‹œì¥ ë¦¬ì„œì¹˜ ë°ì´í„°ë¥¼ ë°˜ì˜í•œ íŠ¸ë Œë“œ ë¶„ì„**

## ì¶œë ¥ ìŠ¤íƒ€ì¼
- ê° ì•„ì´ë””ì–´ëŠ” **êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥**í•˜ê²Œ ì‘ì„±
- ì»¨ì…‰ëª…ì€ **íŠ¸ë Œë””í•˜ê³  ê¸°ì–µì— ë‚¨ëŠ”** ë„¤ì´ë°
- USPëŠ” **ê²½ìŸì‚¬ì™€ ëª…í™•íˆ ì°¨ë³„í™”**ë˜ëŠ” í¬ì¸íŠ¸
- ë§ˆì¼€íŒ… í¬ì¸íŠ¸ëŠ” **ì‹¤ì œ ê´‘ê³  ì¹´í”¼ë¡œ ì‚¬ìš© ê°€ëŠ¥**í•œ ìˆ˜ì¤€
- ë°ì´í„°ì— ê¸°ë°˜í•œ **ë…¼ë¦¬ì  ê·¼ê±°** ì œì‹œ
- **ë¦¬ì„œì¹˜ ë°ì´í„°ì˜ ìµœì‹  íŠ¸ë Œë“œë¥¼ ë°˜ì˜**

## ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
ê° ì‹ ì œí’ˆ ì•„ì´ë””ì–´ëŠ” ë‹¤ìŒ í˜•ì‹ì„ ì—„ê²©íˆ ë”°ë¥´ì„¸ìš”:

ğŸ’¡ ì‹ ì œí’ˆ ì•„ì´ë””ì–´ #N

ì»¨ì…‰ëª…: [ì œí’ˆëª…] ([ì˜ë¬¸ëª…])

ğŸ¯ ì‹ ì œí’ˆ ì»¨ì…‰
"[í•µì‹¬ ë©”ì‹œì§€ë¥¼ ì¸ìš©ë¶€í˜¸ë¡œ ê°•ì¡°]"
[ìƒì„¸ ì„¤ëª… 2-3ë¬¸ì¥]

ğŸ“¦ ì œí’ˆ ìƒì„¸
- í˜•íƒœ: [ë‚´ìš©]
- ì œí˜•: [ë‚´ìš©]
- ìš©ëŸ‰/ê°€ê²©: [ë‚´ìš©]
- í•µì‹¬ ì„±ë¶„: [ë‚´ìš©]
- íŠ¹í—ˆ ê¸°ìˆ : [ë‚´ìš©] (ì„ íƒ)

ğŸ§ª ì„±ë¶„ ë° ì œí˜• ìƒì„¸
- ì£¼ì„±ë¶„: [ì„±ë¶„ëª… (ë†ë„%), íš¨ëŠ¥]
- ë¶€ì„±ë¶„: [ì„±ë¶„ëª… (ë†ë„%), ì—­í• ]
- ì œí˜• ê¸°ìˆ : [ìœ í™” ë°©ì‹, ì•ˆì •í™” ê¸°ìˆ , ì¹¨íˆ¬ ê¸°ìˆ  ë“±]
- pH: [ì ì • pH ë²”ìœ„]
- í…ìŠ¤ì²˜: [ìƒì„¸í•œ ì œí˜•ê° ì„¤ëª…]

ğŸŒŸ í•µì‹¬ USP ğŸ’§
"[ì¸ìš©ë¶€í˜¸ë¡œ ì‹œì‘í•˜ëŠ” ë©”ì¸ USP]"
- [ë¶€ì—° ì„¤ëª… 1]
- [ë¶€ì—° ì„¤ëª… 2]
- [ë¶€ì—° ì„¤ëª… 3]

ğŸ“– ì œí’ˆ ìŠ¤í† ë¦¬
[ì°½ì˜ì ì´ê³  ê°ì„±ì ì¸ ìŠ¤í† ë¦¬í…”ë§]
- ì˜ê°ì˜ ì›ì²œ (ì˜ˆ: ì¹˜ì•™ë§ˆì´ ê³ ì‚°ì§€ëŒ€ ì•„ì¹¨ì´ìŠ¬, ì‹ ë¼ í™”ë‘ì˜ ë¯¸í•™ ë“±)
- ë¸Œëœë“œ ì² í•™ê³¼ ì—°ê²°
- ì†Œë¹„ì ê³µê° í¬ì¸íŠ¸
- 2-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ

ğŸ‘¥ íƒ€ê²Ÿ ê³ ê°ì¸µ
1ì°¨ íƒ€ê²Ÿ | [20ëŒ€ ì„¤ëª…]
2ì°¨ íƒ€ê²Ÿ | [30ëŒ€ ì„¤ëª…] (ì„ íƒ)

ğŸ“¢ ë§ˆì¼€íŒ… í¬ì¸íŠ¸
ë©”ì¸ ì¹´í”¼: "[ê´‘ê³  ì¹´í”¼]"
ì„œë¸Œ ë©”ì‹œì§€:
- "[ì„œë¸Œ ì¹´í”¼ 1]"
- "[ì„œë¸Œ ì¹´í”¼ 2]"
ë°”ì´ëŸ´ ì „ëµ: [SNS ë°”ì´ëŸ´ í¬ì¸íŠ¸]

**ì¤‘ìš”: ë³µì¡í•œ í‘œ(table) í˜•ì‹, ì²´í¬ë°•ìŠ¤(âœ…), ë‹¤ë‹¨ í‘œ êµ¬ì¡°ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ìœ„ í˜•ì‹ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.**

## ì£¼ì˜ì‚¬í•­
- ë¶„ì„ ë°ì´í„°ì˜ ì¥ì /ë‹¨ì ì„ ë°˜ë“œì‹œ ë°˜ì˜
- **ì‹œì¥ ë¦¬ì„œì¹˜ ë°ì´í„°ì˜ ìµœì‹  íŠ¸ë Œë“œë¥¼ ë°˜ì˜** (ì œê³µëœ ê²½ìš°)
- ì¶”ìƒì ì¸ ì œì•ˆ ëŒ€ì‹  êµ¬ì²´ì ì¸ ì œí˜•, ì„±ë¶„, ìš©ëŸ‰ ì œì•ˆ
- **ì„±ë¶„ëª…ê³¼ ë†ë„ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ** (ì˜ˆ: Niacinamide 5%, Hyaluronic Acid 2%)
- ì˜¬ë¦¬ë¸Œì˜ ê°€ê²©ëŒ€ì™€ íƒ€ê²Ÿì¸µì— ë§ëŠ” í˜„ì‹¤ì ì¸ ì œì•ˆ
- í•µì‹¬ ë©”ì‹œì§€ëŠ” ë°˜ë“œì‹œ ì¸ìš©ë¶€í˜¸("")ë¡œ ê°•ì¡°
- **ì œí’ˆ ìŠ¤í† ë¦¬ëŠ” ê°ì„±ì ì´ë©´ì„œë„ ë¸Œëœë“œ ì •ì²´ì„±ê³¼ ì—°ê²°**"""


def call_ai_api(prompt: str, model_info: dict) -> str:
    """AI API í˜¸ì¶œ (Claude/OpenAI ì§€ì›)"""
    provider = model_info.get("provider", "anthropic")
    model_id = model_info.get("id", "")

    if provider == "anthropic":
        return _call_claude_api(prompt, model_id, model_info.get("thinking_budget", 0))
    elif provider == "openai":
        return _call_openai_api(prompt, model_id)
    else:
        return f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” provider: {provider}"


def _call_claude_api(prompt: str, model_id: str, thinking_budget: int = 0) -> str:
    """Claude API í˜¸ì¶œ (Extended Thinking ì§€ì›)"""
    try:
        import anthropic

        api_key = st.secrets.get("ANTHROPIC_API_KEY", "")
        if not api_key:
            return "âŒ ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

        client = anthropic.Anthropic(api_key=api_key)

        if thinking_budget > 0:
            message = client.messages.create(
                model=model_id,
                max_tokens=16000,
                system=SYSTEM_PROMPT,
                thinking={
                    "type": "enabled",
                    "budget_tokens": thinking_budget
                },
                messages=[{"role": "user", "content": prompt}]
            )
            result_text = ""
            for block in message.content:
                if block.type == "text":
                    result_text += block.text
            return result_text
        else:
            message = client.messages.create(
                model=model_id,
                max_tokens=4096,
                system=SYSTEM_PROMPT,
                temperature=1.0,
                messages=[{"role": "user", "content": prompt}]
            )
            return message.content[0].text

    except ImportError:
        return "âŒ anthropic íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install anthropic"
    except Exception as e:
        return f"âŒ Claude API ì˜¤ë¥˜: {str(e)}"


def _call_openai_api(prompt: str, model_id: str) -> str:
    """OpenAI API í˜¸ì¶œ"""
    try:
        from openai import OpenAI

        api_key = st.secrets.get("OPENAI_API_KEY", "")
        if not api_key:
            return "âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

        client = OpenAI(api_key=api_key)

        response = client.chat.completions.create(
            model=model_id,
            max_completion_tokens=4096,
            temperature=1.0,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ]
        )
        return response.choices[0].message.content

    except ImportError:
        return "âŒ openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai"
    except Exception as e:
        return f"âŒ OpenAI API ì˜¤ë¥˜: {str(e)}"


def load_all_research_files() -> dict:
    """
    ë¦¬ì„œì¹˜ íƒ­ì˜ ëª¨ë“  md íŒŒì¼ ë¡œë“œ

    Returns:
        dict: {
            'trendier': [(filename, content), ...],
            'hwahae': [(filename, content), ...],
            'deepresearch': [(filename, content), ...]
        }
    """
    research_data = {
        'trendier': [],
        'hwahae': [],
        'deepresearch': []
    }

    for category in research_data.keys():
        category_dir = REPORTS_DIR / category
        if category_dir.exists():
            for md_file in sorted(category_dir.glob("*.md")):
                try:
                    content = md_file.read_text(encoding="utf-8")
                    research_data[category].append((md_file.name, content))
                except UnicodeDecodeError:
                    # cp949 fallback
                    try:
                        content = md_file.read_text(encoding="cp949")
                        research_data[category].append((md_file.name, content))
                    except Exception:
                        pass
                except Exception as e:
                    print(f"Error loading {md_file}: {e}")

    return research_data


def format_research_section(research_data: dict) -> str:
    """
    ë¦¬ì„œì¹˜ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ ì„¹ì…˜ìœ¼ë¡œ í¬ë§·íŒ…

    Returns:
        str: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¦¬ì„œì¹˜ ì„¹ì…˜
    """
    if not any(research_data.values()):
        return ""

    md = "\n\n---\n\n# ì‹œì¥ ë¦¬ì„œì¹˜ ë°ì´í„°\n\n"

    # ì¹´í…Œê³ ë¦¬ë³„ ë¦¬ì„œì¹˜ ì¶”ê°€
    category_names = {
        'trendier': 'ğŸ” Trendier ë¦¬í¬íŠ¸',
        'hwahae': 'ğŸ’§ í™”í•´ ë¦¬í¬íŠ¸',
        'deepresearch': 'ğŸ¤– ë”¥ë¦¬ì„œì¹˜ (Claude Code)'
    }

    for category, files in research_data.items():
        if files:
            md += f"## {category_names[category]}\n\n"
            for filename, content in files:
                md += f"### ğŸ“„ {filename}\n\n"
                md += content + "\n\n"

    return md


st.set_page_config(page_title="ì‹ ì œí’ˆ ì•„ì´ë””ì–´ ìƒì„±", page_icon="ğŸ’¡", layout="wide")

@st.cache_resource
def get_db():
    return DatabaseManager(DB_PATH)

db = get_db()


def parse_goodsno_input(text: str) -> list:
    """GOODSNO ì…ë ¥ íŒŒì‹± (ì¤„ë°”ê¿ˆ, ì½¤ë§ˆ, ê³µë°± êµ¬ë¶„)"""
    # ì¤„ë°”ê¿ˆ, ì½¤ë§ˆ, ê³µë°±ì„ êµ¬ë¶„ìë¡œ ë¶„ë¦¬
    codes = re.split(r'[\n,\s]+', text.strip())
    # ë¹ˆ ë¬¸ìì—´ ì œê±° ë° ì¤‘ë³µ ì œê±°
    return list(dict.fromkeys([c.strip() for c in codes if c.strip()]))


def generate_oliveyoung_prompt(analyses: list, selected_research_categories: list = None) -> str:
    """
    ì˜¬ë¦¬ë¸Œì˜ ë¶„ì„ ë°ì´í„° ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„± (ë¦¬ì„œì¹˜ ë°ì´í„° í¬í•¨)

    Args:
        analyses: ê²½ìŸì‚¬ ë¶„ì„ ë°ì´í„°
        selected_research_categories: ì„ íƒëœ ë¦¬ì„œì¹˜ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸
            ["Trendier ë¦¬í¬íŠ¸", "í™”í•´ ë¦¬í¬íŠ¸", "ë”¥ë¦¬ì„œì¹˜"]
    """
    if not analyses:
        return ""

    # ì˜¬ë¦¬ë¸Œì˜ ì œí’ˆ ì •ë³´ë¥¼ í•œ ë²ˆë§Œ ì¡°íšŒí•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ì„±ëŠ¥ ìµœì í™”)
    oliveyoung_products_dict = {
        p['product_code']: p
        for p in db.get_oliveyoung_products()
    }

    # ì œí’ˆ ì •ë³´ ìˆ˜ì§‘
    products_info = []
    all_strengths = []  # (í‚¤ì›Œë“œ, ì›ë¬¸) íŠœí”Œ
    all_weaknesses = []  # (í‚¤ì›Œë“œ, ì›ë¬¸) íŠœí”Œ
    all_usp = []
    all_review_samples = []
    categories = set()
    prices = []

    for a in analyses:
        product_code = a.get('product_code', '')

        products_info.append({
            'code': product_code,
            'brand': a.get('brand', ''),
            'name': a.get('name', ''),
            'total_reviews': a.get('total_reviews', 0),
            'positive_ratio': a.get('positive_ratio', 0)
        })

        # ì¥ì  ìˆ˜ì§‘ (í‚¤ì›Œë“œì™€ ì›ë¬¸ í•¨ê»˜)
        for s in a.get('strengths', []) or []:
            if ':' in s:
                kw = s.split(':')[0].strip()
                detail = s.split(':', 1)[1].strip() if ':' in s else s
            else:
                kw = s[:15].strip()
                detail = s
            all_strengths.append((kw, detail))

        # ë‹¨ì  ìˆ˜ì§‘ (í‚¤ì›Œë“œì™€ ì›ë¬¸ í•¨ê»˜)
        for w in a.get('weaknesses', []) or []:
            if ':' in w:
                kw = w.split(':')[0].strip()
                detail = w.split(':', 1)[1].strip() if ':' in w else w
            else:
                kw = w[:15].strip()
                detail = w
            all_weaknesses.append((kw, detail))

        # USP ìˆ˜ì§‘
        for usp in a.get('usp_candidates', []) or []:
            cat = usp.get('category', 'other')
            sentence = usp.get('sentence', '')
            keywords = usp.get('trigger_words', []) or []
            if sentence and keywords:
                all_usp.append({
                    'category': cat,
                    'keyword': keywords[0] if keywords else '',
                    'sentence': sentence
                })

        # ë¦¬ë·° ìƒ˜í”Œ ìˆ˜ì§‘
        for r in (a.get('review_samples', []) or [])[:3]:
            all_review_samples.append(r.get('content', '')[:100])

        # ì˜¬ë¦¬ë¸Œì˜ ì œí’ˆ ì •ë³´ì—ì„œ ì¹´í…Œê³ ë¦¬, ê°€ê²© ê°€ì ¸ì˜¤ê¸° (ë”•ì…”ë„ˆë¦¬ ì¡°íšŒë¡œ ìµœì í™”)
        if product_code and product_code in oliveyoung_products_dict:
            p = oliveyoung_products_dict[product_code]
            if p.get('category'):
                categories.add(p['category'])
            if p.get('price'):
                prices.append(p['price'])

    # ì¥ì /ë‹¨ì  ë¹ˆë„ ë¶„ì„
    def get_freq_with_samples(items):
        """ë¹ˆë„ ë¶„ì„ + ëŒ€í‘œ ë¦¬ë·° ì¶”ì¶œ"""
        keyword_counts = Counter([item[0] for item in items])
        keyword_samples = {}
        for kw, detail in items:
            if kw not in keyword_samples:
                keyword_samples[kw] = detail
        result = []
        for kw, cnt in keyword_counts.most_common(8):
            result.append({
                'keyword': kw,
                'count': cnt,
                'sample': keyword_samples.get(kw, '')[:80]
            })
        return result

    strength_data = get_freq_with_samples(all_strengths)
    weakness_data = get_freq_with_samples(all_weaknesses)

    # USP ì¹´í…Œê³ ë¦¬ë³„ ì •ë¦¬
    usp_by_cat = {}
    for usp in all_usp:
        cat = usp['category']
        if cat not in usp_by_cat:
            usp_by_cat[cat] = []
        existing_keywords = [u['keyword'] for u in usp_by_cat[cat]]
        if usp['keyword'] not in existing_keywords and len(usp_by_cat[cat]) < 2:
            usp_by_cat[cat].append(usp)

    # ì¹´í…Œê³ ë¦¬ í•œê¸€ëª… ë§¤í•‘
    category_names = {
        'visual': 'ì‹œê°ì  íŠ¹ì§•',
        'tactile': 'ì´‰ê°/ì œí˜•',
        'action': 'ì‚¬ìš© ì‹œ ë³€í™”',
        'olfactory': 'í–¥ íŠ¹ì§•',
        'design': 'ë””ìì¸/íœ´ëŒ€ì„±',
        'reaction': 'ì†Œë¹„ì ë°˜ì‘',
        'viral': 'ë°”ì´ëŸ´/SNS'
    }

    # ê°€ê²© ì •ë³´
    price_info = ""
    if prices:
        avg_price = int(sum(prices) / len(prices))
        min_price = min(prices)
        max_price = max(prices)
        price_info = f"- ê²½ìŸ ì œí’ˆ ê°€ê²©ëŒ€: {min_price:,}ì› ~ {max_price:,}ì›\n- í‰ê· ê°€: {avg_price:,}ì›"
    else:
        price_info = "- ê°€ê²© ì •ë³´ ì—†ìŒ"

    # ì¹´í…Œê³ ë¦¬ ë¬¸ìì—´
    category_str = ', '.join(categories) if categories else 'ë¯¸ë¶„ë¥˜'

    # === í”„ë¡¬í”„íŠ¸ ìƒì„± ===
    md = f"""# ì—­í• 
ë‹¹ì‹ ì€ ì˜¬ë¦¬ë¸Œì˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ë¥¼ ê¸°íší•˜ëŠ” **í™”ì¥í’ˆ ì‹ ì œí’ˆ ê¸°íšì**ì…ë‹ˆë‹¤.
ì•„ë˜ ë¦¬ë·° ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ì¶œì‹œ ê°€ëŠ¥í•œ ì‹ ì œí’ˆ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

---

# ë¶„ì„ ë°ì´í„°

## ì¹´í…Œê³ ë¦¬
**{category_str}**

## ë¶„ì„ ì œí’ˆ ({len(analyses)}ê°œ)
"""

    for i, p in enumerate(products_info, 1):
        md += f"{i}. [{p['brand']}] {p['name']} - ë¦¬ë·° {p['total_reviews']:,}ê°œ, ê¸ì •ë¥  {p['positive_ratio']}%\n"

    md += f"""
## ì†Œë¹„ìê°€ ì¢‹ì•„í•˜ëŠ” ì  (ì¥ì )
"""
    if strength_data:
        for i, s in enumerate(strength_data[:6], 1):
            md += f"{i}. **{s['keyword']}** ({s['count']}íšŒ ì–¸ê¸‰)\n"
            if s['sample']:
                md += f"   - ëŒ€í‘œ ë¦¬ë·°: \"{s['sample']}\"\n"
    else:
        md += "- ë¶„ì„ëœ ì¥ì ì´ ì—†ìŠµë‹ˆë‹¤.\n"

    md += f"""
## ì†Œë¹„ì ë¶ˆë§Œ (ë‹¨ì  = ê°œì„  ê¸°íšŒ)
"""
    if weakness_data:
        for i, w in enumerate(weakness_data[:6], 1):
            md += f"{i}. **{w['keyword']}** ({w['count']}íšŒ ì–¸ê¸‰)\n"
            if w['sample']:
                md += f"   - ëŒ€í‘œ ë¦¬ë·°: \"{w['sample']}\"\n"
    else:
        md += "- ë¶„ì„ëœ ë‹¨ì ì´ ì—†ìŠµë‹ˆë‹¤.\n"

    md += f"""
## ì°¨ë³„í™” í¬ì¸íŠ¸ (USP í›„ë³´)
"""
    if usp_by_cat:
        for cat, items in usp_by_cat.items():
            cat_name = category_names.get(cat, cat)
            for item in items:
                md += f"- [{cat_name}] **{item['keyword']}**: \"{item['sentence'][:60]}...\"\n"
    else:
        md += "- USP í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\n"

    md += f"""
## ê°€ê²© ì •ë³´
{price_info}

---

# ì‹ ì œí’ˆ ì•„ì´ë””ì–´ ìš”ì²­

ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ì œì•ˆí•´ì£¼ì„¸ìš”:

1. **ì‹ ì œí’ˆ ì»¨ì…‰**: ê³µí†µ ì¥ì ì„ ì‚´ë¦¬ê³  ë‹¨ì ì„ ë³´ì™„í•œ ì œí’ˆ ì•„ì´ë””ì–´
2. **ì»¨ì…‰ëª…**: ì œí’ˆì˜ í•µì‹¬ ê°€ì¹˜ë¥¼ ë‹´ì€ ë¸Œëœë“œëª…/ì œí’ˆëª… (ì˜ˆ: ì•„ì¿ ì•„ë½ ì œë¡œ, ê¸€ë¡œìš°ë“œë¡­ ë“±)
3. **í•µì‹¬ USP**: ê²½ìŸ ì œí’ˆê³¼ ì°¨ë³„í™”í•  ìˆ˜ ìˆëŠ” í¬ì¸íŠ¸
4. **ì„±ë¶„ ë° ì œí˜•**: êµ¬ì²´ì ì¸ ì„±ë¶„ëª…, ë†ë„, ì œí˜• ê¸°ìˆ  ì œì•ˆ
5. **ì œí’ˆ ìŠ¤í† ë¦¬**: ê°ì„±ì ì´ê³  ì°½ì˜ì ì¸ ìŠ¤í† ë¦¬í…”ë§
6. **íƒ€ê²Ÿ ê³ ê°ì¸µ**: ì´ ì œí’ˆì´ ê°€ì¥ ì–´í•„í•  ê³ ê°ì¸µ
7. **ë§ˆì¼€íŒ… í¬ì¸íŠ¸**: ì†Œë¹„ìì—ê²Œ ê°•ì¡°í•  ë©”ì‹œì§€
8. **ì•„ì´ë””ì–´ 3ê°œ**: ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ ì œí’ˆ ì•„ì´ë””ì–´ 3ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”

## ì‹œì¥ ë¦¬ì„œì¹˜ ë¦¬í¬íŠ¸ í™œìš©
**ë¦¬í¬íŠ¸ê°€ ë³„ë„ë¡œ ì²¨ë¶€ëœ ê²½ìš°**, ì•„ë˜ ì‚¬í•­ì„ ì°¸ê³ í•˜ì—¬ ì•„ì´ë””ì–´ë¥¼ ë³´ì™„í•˜ì„¸ìš”:
- ìµœì‹  í™”ì¥í’ˆ íŠ¸ë Œë“œ (ì„±ë¶„, ì œí˜•, ë””ìì¸)
- ì†Œë¹„ì ì„ í˜¸ë„ ë³€í™”
- ê²½ìŸ ë¸Œëœë“œì˜ ì‹ ì œí’ˆ ë™í–¥
- í™”í•´, Trendier ë“± í”Œë«í¼ì˜ ì¸ì‚¬ì´íŠ¸

**ë¦¬í¬íŠ¸ê°€ ì²¨ë¶€ë˜ì§€ ì•Šì€ ê²½ìš°**, ë‹¹ì‹ ì˜ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ì¡°ì‚¬í•˜ì—¬ ë°˜ì˜í•˜ì„¸ìš”:
- 2025-2026ë…„ ìµœì‹  í™”ì¥í’ˆ íŠ¸ë Œë“œ (K-ë·°í‹°, ê¸€ë¡œë²Œ ì‹œì¥)
- í™”í•´, Trendier ë“± í”Œë«í¼ì˜ ìµœì‹  ë¦¬ë·° íŠ¸ë Œë“œ
- ì¸ê¸° ì„±ë¶„ ë° ì œí˜• ê¸°ìˆ  (ì˜ˆ: ë°œíš¨ ì„±ë¶„, í”„ë¡œë°”ì´ì˜¤í‹±ìŠ¤, ë‚˜ì´ì•„ì‹ ì•„ë§ˆì´ë“œ ë“±)
- MZì„¸ëŒ€ê°€ ì„ í˜¸í•˜ëŠ” ì œí’ˆ íŠ¹ì§•
- ì§€ì†ê°€ëŠ¥ì„±, ë¹„ê±´, í´ë¦°ë·°í‹° ë“± ìœ¤ë¦¬ì  ì†Œë¹„ íŠ¸ë Œë“œ

## ì»¨ì…‰ëª… ì‘ì„± ê°€ì´ë“œ
- ì˜ë¬¸+í•œê¸€ ì¡°í•© ë˜ëŠ” ìˆœí•œê¸€ ëª¨ë‘ ê°€ëŠ¥
- ì œí’ˆì˜ í•µì‹¬ íš¨ëŠ¥ì´ë‚˜ íŠ¹ì§•ì„ ì§ê´€ì ìœ¼ë¡œ í‘œí˜„
- ì˜¬ë¦¬ë¸Œì˜ ê°ì„±ì— ë§ëŠ” íŠ¸ë Œë””í•œ ë„¤ì´ë°
- ì˜ˆì‹œ: "ì•„ì¿ ì•„ë½ ì œë¡œ", "ì‹œì¹´ë°¤ ë¦¬í˜ì–´", "ê¸€ë¡œìš° ë¶€ìŠ¤í„°" ë“±
- **ì˜ë¬¸ ìŠ¤íƒ€ì¼**: Aqualock Zero, Glow Drop, Cica Calm ë“±
- **í•œê¸€ ìŠ¤íƒ€ì¼**: ë¬¼ê´‘ì ¤ë¦¬, ì´‰ì´‰ë‹´, ì§„ì •ìˆ˜ ë“±
- **í˜¼í•© ìŠ¤íƒ€ì¼**: ìˆ˜ë¶„ë½ ì œë¡œ, ê¸€ë¡œìš° ë¬¼ê´‘íŒ© ë“±

## ì„±ë¶„ ì œì•ˆ ê°€ì´ë“œ
- êµ¬ì²´ì ì¸ ì„±ë¶„ëª…ê³¼ ë†ë„ ì œì‹œ (ì˜ˆ: Niacinamide 5%, Centella Asiatica Extract 10%)
- ì„±ë¶„ì˜ íš¨ëŠ¥ê³¼ ê·¼ê±° ì„¤ëª…
- ì œí˜• ê¸°ìˆ  êµ¬ì²´ì  ì œì‹œ (ì˜ˆ: ë¦¬í¬ì¢€ ìº¡ìŠí™”, ë‚˜ë…¸ ì—ë©€ì ¼ ë“±)
- ë¦¬ì„œì¹˜ ë¦¬í¬íŠ¸ì˜ íŠ¸ë Œë“œ ì„±ë¶„ ë°˜ì˜ (ì²¨ë¶€ëœ ê²½ìš°)

## ì œí’ˆ ìŠ¤í† ë¦¬ ê°€ì´ë“œ
- ì°½ì˜ì ì´ê³  ê°ì„±ì ì¸ ìŠ¤í† ë¦¬í…”ë§
- ì˜ˆì‹œ:
  * "ì¹˜ì•™ë§ˆì´ ê³ ì‚°ì§€ëŒ€ ì‚¬ëŒë“¤ì€ ì•„ì¹¨ì´ìŠ¬ë¡œ ì„¸ìˆ˜í•˜ëŠ” ê²ƒì´ í”¼ë¶€ ê´€ë¦¬ì˜ ë¹„ê²°"
  * "ì‹ ë¼ì‹œëŒ€ í™”ë‘ì€ 'ì™¸ë©´ì˜ ì•„ë¦„ë‹¤ì›€ì€ ë‚´ë©´ì— íˆ¬ì˜ëœë‹¤'ê³  ë¯¿ì—ˆê¸°ì—..."
  * "ì œì£¼ í™”ì‚°ì†¡ì´ì˜ ë¯¸ì„¸í•œ ê¸°ê³µì€ í”¼ë¶€ ë…¸íë¬¼ì„ í¡ì°©í•˜ëŠ” ìì—°ì˜ ì§€í˜œ"
- ë¸Œëœë“œ ì² í•™ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
- 2-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ

ê° ì•„ì´ë””ì–´ëŠ” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ì¶œë ¥ í˜•ì‹
ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ ì œëª©ìœ¼ë¡œ ì‹œì‘í•´ì£¼ì„¸ìš”:
# ğŸ§´ ì‹ ì œí’ˆ ì•„ì´ë””ì–´ ìƒì„±
"""

    # === ë¦¬ì„œì¹˜ ë°ì´í„° ì¶”ê°€ (ì„ íƒëœ ì¹´í…Œê³ ë¦¬ë§Œ) ===
    if selected_research_categories:
        # ì¹´í…Œê³ ë¦¬ëª… ë§¤í•‘
        category_map = {
            "Trendier ë¦¬í¬íŠ¸": "trendier",
            "í™”í•´ ë¦¬í¬íŠ¸": "hwahae",
            "ë”¥ë¦¬ì„œì¹˜": "deepresearch"
        }

        # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
        selected_keys = [category_map[cat] for cat in selected_research_categories if cat in category_map]

        research_data = load_all_research_files()
        filtered_data = {k: v for k, v in research_data.items() if k in selected_keys}

        research_section = format_research_section(filtered_data)
        md += research_section

    return md


def render_oliveyoung_tab():
    """ì˜¬ë¦¬ë¸Œì˜ ê¸°ë°˜ ì œì•ˆ íƒ­ ë Œë”ë§"""
    st.subheader("ì˜¬ë¦¬ë¸Œì˜ ì œí’ˆ ë¶„ì„ ê¸°ë°˜ ì‹ ì œí’ˆ ì•„ì´ë””ì–´")
    st.caption("ë¶„ì„ ì™„ë£Œëœ GOODSNOë¥¼ ì…ë ¥í•˜ë©´ ì¥ë‹¨ì , USP, ë§ˆì¼€íŒ…í¬ì¸íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì‹ ì œí’ˆ ì•„ì´ë””ì–´ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.")

    # ë¶„ì„ ì™„ë£Œëœ ì œí’ˆ ìˆ˜ í‘œì‹œ
    analyzed_codes = db.get_analyzed_product_codes()
    st.info(f"í˜„ì¬ ë¶„ì„ ì™„ë£Œëœ ì œí’ˆ: **{len(analyzed_codes)}ê°œ**")

    # GOODSNO ì…ë ¥
    st.markdown("**GOODSNO ì…ë ¥** (ì¤„ë°”ê¿ˆ, ì½¤ë§ˆ, ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)")

    goodsno_input = st.text_area(
        "GOODSNO ì…ë ¥",
        placeholder="A000000243499\nA000000123456\nA000000789012",
        height=150,
        help="ì˜¬ë¦¬ë¸Œì˜ ìƒí’ˆì½”ë“œ(GOODSNO)ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì—¬ëŸ¬ ê°œë¥¼ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        label_visibility="collapsed"
    )

    st.divider()

    # ë‘ ê°œì˜ ë²„íŠ¼ ë‚˜ë€íˆ ë°°ì¹˜
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### ğŸ“‹ ë¬´ë£Œ (í”„ë¡¬í”„íŠ¸ ë³µì‚¬)")

        if st.button("í”„ë¡¬í”„íŠ¸ ìƒì„±", type="secondary", use_container_width=True,
                    help="í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ í™”ë©´ì— í‘œì‹œ"):
            # ë²„íŠ¼ í´ë¦­ ì‹œ ì…ë ¥ê°’ íŒŒì‹±
            input_codes = parse_goodsno_input(goodsno_input) if goodsno_input else []

            if not input_codes:
                st.error("GOODSNOë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                valid_codes = [c for c in input_codes if c in analyzed_codes]
                invalid_codes = [c for c in input_codes if c not in analyzed_codes]

                if invalid_codes:
                    st.warning(f"ë¯¸ë¶„ì„ {len(invalid_codes)}ê°œ ì œì™¸")

                if not valid_codes:
                    st.error("ë¶„ì„ ì™„ë£Œëœ GOODSNOê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    with st.spinner("í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘..."):
                        analyses = db.get_review_analyses_by_codes(valid_codes)

                    if analyses:
                        # í”„ë¡¬í”„íŠ¸ ìƒì„± (ë¦¬ì„œì¹˜ ì œì™¸)
                        prompt = generate_oliveyoung_prompt(analyses)

                        # session_stateì— ì €ì¥
                        st.session_state['free_prompt'] = prompt
                        st.success(f"âœ… {len(analyses)}ê°œ ì œí’ˆ í”„ë¡¬í”„íŠ¸ ìƒì„±!")
                        st.rerun()
                    else:
                        st.error("ë¶„ì„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        # === ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ í‘œì‹œ ===
        if 'free_prompt' in st.session_state and st.session_state['free_prompt']:
            st.divider()

            prompt = st.session_state['free_prompt']

            # í”„ë¡¬í”„íŠ¸ í‘œì‹œ (ì ‘ì„ ìˆ˜ ìˆëŠ” expander)
            with st.expander("ğŸ“„ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°", expanded=True):
                st.code(prompt, language="markdown")

            st.caption("ğŸ’¡ ìœ„ ì½”ë“œ ë¸”ë¡ ìš°ì¸¡ ìƒë‹¨ì˜ ë³µì‚¬ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë³µì‚¬í•˜ì„¸ìš”")

    with col2:
        st.markdown("#### ğŸš€ ìœ ë£Œ (API ìë™ ìƒì„±)")

        # ë¦¬ì„œì¹˜ ì„ íƒ (ë©€í‹°ì…€ë ‰íŠ¸)
        selected_research_api = st.multiselect(
            "í¬í•¨í•  ë¦¬ì„œì¹˜ ì„ íƒ",
            options=["Trendier ë¦¬í¬íŠ¸", "í™”í•´ ë¦¬í¬íŠ¸", "ë”¥ë¦¬ì„œì¹˜"],
            default=["Trendier ë¦¬í¬íŠ¸", "í™”í•´ ë¦¬í¬íŠ¸", "ë”¥ë¦¬ì„œì¹˜"],  # APIëŠ” ëª¨ë“  ë¦¬ì„œì¹˜ ê¸°ë³¸ ì„ íƒ
            help="ì„ íƒí•œ ë¦¬ì„œì¹˜ê°€ ìë™ìœ¼ë¡œ AIì—ê²Œ ì „ë‹¬ë©ë‹ˆë‹¤",
            key="research_api"
        )

        # ë²„íŠ¼ ë¨¼ì € ë°°ì¹˜
        api_clicked = st.button("AI ì•„ì´ë””ì–´ ìƒì„±", type="primary", use_container_width=True,
                    help="AI APIë¡œ ì•„ì´ë””ì–´ ìë™ ìƒì„± (Claude/GPT)")

        # ëª¨ë¸ ì„ íƒ (ìš°ì¸¡ í•˜ë‹¨ì— ì‘ê²Œ - 1/3 í¬ê¸°)
        _, model_col = st.columns([2, 1])
        with model_col:
            selected_model = st.selectbox(
                "ëª¨ë¸",
                options=list(AI_MODELS.keys()),
                index=0,
                key="model_select",
                label_visibility="collapsed"
            )
            model_info = AI_MODELS[selected_model]
            st.caption(f"ì˜ˆìƒ: {model_info['cost']}")

        if api_clicked:
            input_codes = parse_goodsno_input(goodsno_input) if goodsno_input else []

            if not input_codes:
                st.error("GOODSNOë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                valid_codes = [c for c in input_codes if c in analyzed_codes]
                invalid_codes = [c for c in input_codes if c not in analyzed_codes]

                if invalid_codes:
                    st.warning(f"ë¯¸ë¶„ì„ {len(invalid_codes)}ê°œ ì œì™¸")

                if not valid_codes:
                    st.error("ë¶„ì„ ì™„ë£Œëœ GOODSNOê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    thinking_budget = model_info.get('thinking_budget', 0)
                    thinking_msg = " (Extended Thinking)" if thinking_budget > 0 else ""
                    with st.spinner(f"{selected_model}ë¡œ ì•„ì´ë””ì–´ ìƒì„± ì¤‘...{thinking_msg} (ì•½ 30-60ì´ˆ ì†Œìš”)"):
                        analyses = db.get_review_analyses_by_codes(valid_codes)

                        if analyses:
                            prompt = generate_oliveyoung_prompt(analyses, selected_research_api)
                            result = call_ai_api(prompt, model_info)
                            st.session_state['api_result'] = result
                            st.session_state['oliveyoung_prompt'] = None  # í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”

                            # ìë™ ì €ì¥ (ì €ì¥ëœ ì œì•ˆ íƒ­)
                            if result and not result.startswith("âŒ"):
                                proposal_title = f"AI ì œì•ˆ ({selected_model}) - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                                db.add_proposal({
                                    'title': proposal_title,
                                    'category': 'ì˜¬ë¦¬ë¸Œì˜ ë¶„ì„',
                                    'concept_description': result,
                                    'key_features': [f"ë¶„ì„ ì œí’ˆ: {len(valid_codes)}ê°œ", f"ëª¨ë¸: {selected_model}"],
                                    'notes': f"GOODSNO: {', '.join(valid_codes[:5])}{'...' if len(valid_codes) > 5 else ''}"
                                })
                                st.session_state['last_saved_title'] = proposal_title
                                st.success(f"âœ… AI ì•„ì´ë””ì–´ ìƒì„± ì™„ë£Œ!{thinking_msg} (ìë™ ì €ì¥ë¨)")
                            else:
                                st.error(result)
                        else:
                            st.error("ë¶„ì„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # === ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ í‘œì‹œ (ë¬´ë£Œ) ===
    if 'oliveyoung_prompt' in st.session_state and st.session_state['oliveyoung_prompt']:
        prompt = st.session_state['oliveyoung_prompt']

        st.divider()
        st.markdown("## ğŸ“‹ Claude/Gemini/GPT í”„ë¡¬í”„íŠ¸")
        st.caption("ì˜¤ë¥¸ìª½ ìƒë‹¨ ğŸ“‹ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë³µì‚¬ë©ë‹ˆë‹¤. â†’ Claude/GPTì— ë¶™ì—¬ë„£ê¸° (Ctrl+V)")

        st.code(prompt, language="markdown")

    # === API ê²°ê³¼ í‘œì‹œ (ìœ ë£Œ) ===
    if 'api_result' in st.session_state and st.session_state['api_result']:
        result = st.session_state['api_result']

        st.divider()
        st.markdown("## ğŸš€ AI ìƒì„± ì•„ì´ë””ì–´")

        # Markdown ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        col_title, col_download = st.columns([3, 1])
        with col_title:
            if 'last_saved_title' in st.session_state:
                st.caption(f"ğŸ’¾ ì €ì¥ë¨: {st.session_state['last_saved_title']}")
        with col_download:
            # Markdown íŒŒì¼ ìƒì„±
            md_content = f"""# ì‹ ì œí’ˆ ì•„ì´ë””ì–´
> ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M')}

---

{result}
"""
            st.download_button(
                label="ğŸ“¥ Markdown ë‹¤ìš´ë¡œë“œ",
                data=md_content,
                file_name=f"ì‹ ì œí’ˆ_ì•„ì´ë””ì–´_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
                mime="text/markdown"
            )

        st.markdown(result)


def main():
    st.title("ğŸ’¡ ì‹ ì œí’ˆ ì•„ì´ë””ì–´ ìƒì„±")

    # í†µê³„ ìš”ì•½
    col1, col2 = st.columns(2)
    with col1:
        analyzed_count = len(db.get_analyzed_product_codes())
        st.metric("ë¶„ì„ ì™„ë£Œ ì œí’ˆ", f"{analyzed_count}ê°œ")
    with col2:
        proposals = db.get_proposals()
        st.metric("ì €ì¥ëœ ì œì•ˆ", f"{len(proposals)}ê°œ")

    st.divider()

    # íƒ­ êµ¬ì„±
    tab_oliveyoung, tab_saved = st.tabs([
        "ğŸ›’ ê²½ìŸì‚¬ ë¶„ì„ ê¸°ë°˜", "ğŸ’¾ ì €ì¥ëœ ì•„ì´ë””ì–´"
    ])

    with tab_oliveyoung:
        render_oliveyoung_tab()

    with tab_saved:
        st.subheader("ì €ì¥ëœ ì‹ ì œí’ˆ ì•„ì´ë””ì–´")

        # ìƒˆ ì œì•ˆ ì¶”ê°€ í¼
        with st.expander("â• ìƒˆ ì œì•ˆ ì¶”ê°€"):
            with st.form("new_proposal"):
                title = st.text_input("ì œì•ˆ ì œëª© *")
                category = st.selectbox("ì¹´í…Œê³ ë¦¬", options=PRODUCT_CATEGORIES)
                concept = st.text_area("ì»¨ì…‰ ì„¤ëª…", height=100)
                features = st.text_area("í•µì‹¬ íŠ¹ì§• (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)", height=100)
                notes = st.text_area("ë©”ëª¨", height=80)

                if st.form_submit_button("ğŸ’¾ ì €ì¥", width='stretch'):
                    if not title:
                        st.error("ì œëª©ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
                    else:
                        db.add_proposal({
                            'title': title,
                            'category': category,
                            'concept_description': concept,
                            'key_features': [f.strip() for f in features.split('\n') if f.strip()],
                            'notes': notes
                        })
                        st.success("âœ… ì œì•ˆì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.rerun()

        # ì €ì¥ëœ ì œì•ˆ ëª©ë¡
        proposals = db.get_proposals()

        if not proposals:
            st.info("ì €ì¥ëœ ì œì•ˆì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for proposal in proposals:
                with st.expander(f"ğŸ’¡ {proposal['title']} ({proposal['category']})"):
                    if proposal.get('concept_description'):
                        st.markdown("**ì»¨ì…‰:**")
                        st.write(proposal['concept_description'])

                    if proposal.get('key_features'):
                        st.markdown("**í•µì‹¬ íŠ¹ì§•:**")
                        for feature in proposal['key_features']:
                            st.markdown(f"- {feature}")

                    if proposal.get('notes'):
                        st.markdown("**ë©”ëª¨:**")
                        st.write(proposal['notes'])

                    st.caption(f"ìƒì„±ì¼: {proposal.get('created_at', '-')}")

                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"del_prop_{proposal['id']}"):
                        db.delete_proposal(proposal['id'])
                        st.rerun()


if __name__ == "__main__":
    main()
