"""
ë¦¬ë·° ì¥ë‹¨ì  ë¶„ì„ ëª¨ë“ˆ (ë¬¸ë§¥ ê¸°ë°˜)
- ë¶€ì •ì–´ ì²˜ë¦¬ë¡œ ë¬¸ë§¥ íŒŒì•… ("ìê·¹ ì—†ì´" = ê¸ì •)
- ë§ˆì¼€íŒ… í¬ì¸íŠ¸ ë¶„ì„ (ë°˜ë³µ í‚¤ì›Œë“œ, ê²½ìŸì œí’ˆ ë¹„êµ)
"""
import re
from collections import Counter
from typing import List, Dict, Tuple, Set
from dataclasses import dataclass, field


# ë¶€ì •ì–´ íŒ¨í„´ (í‚¤ì›Œë“œ ì•ì— ì˜¤ë©´ ì˜ë¯¸ ë°˜ì „)
NEGATION_PATTERNS = [
    r'ì—†', r'ì•Š', r'ì•ˆ\s', r'ëª»\s', r'ì•„ë‹ˆ', r'NO', r'no',
    r'ì „í˜€', r'ë³„ë¡œ', r'ê·¸ë‹¤ì§€', r'ë”±íˆ',
]

# ê¸ì • ìˆ˜ì‹ì–´ íŒ¨í„´ (ì´ ë‹¨ì–´ ë’¤ì— í‚¤ì›Œë“œê°€ ì˜¤ë©´ ê¸ì •)
POSITIVE_MODIFIER_PATTERNS = [
    r'ì¢‹ì€', r'ì¢‹ì•„', r'ì¢‹ê³ ', r'ì¢‹ìŒ', r'ê´œì°®', r'ì€ì€', r'ë¶€ë“œëŸ¬', r'ìƒì¾Œ', r'í–¥ê¸‹',
]

# ê¸ì • í‚¤ì›Œë“œ (í™”ì¥í’ˆ ê´€ë ¨)
POSITIVE_KEYWORDS = {
    # íš¨ê³¼/ê²°ê³¼
    'ì¢‹ì•„ìš”': 1.0, 'ì¢‹ì•„': 1.0, 'ì¢‹ìŒ': 1.0, 'ìµœê³ ': 1.2, 'ëŒ€ë°•': 1.2,
    'êµ¿': 1.0, 'ì§±': 1.0, 'ì™„ì „': 0.8, 'ì§„ì§œ': 0.6,
    'íš¨ê³¼': 0.8, 'ê°œì„ ': 1.0, 'ì¢‹ì•„ì¡Œ': 1.0, 'ë‚˜ì•„ì¡Œ': 1.0,
    # ë³´ìŠµ/ìˆ˜ë¶„
    'ì´‰ì´‰': 1.2, 'ë³´ìŠµ': 1.0, 'ìˆ˜ë¶„': 0.8, 'ì´‰ì´‰í•´': 1.2, 'ì´‰ì´‰í•˜ê³ ': 1.2,
    # í¡ìˆ˜
    'í¡ìˆ˜': 0.8, 'ë¹ ë¥¸í¡ìˆ˜': 1.0, 'ìŠ¤ë©°': 0.8, 'í¡ìˆ˜ë¹ ë¦„': 1.0,
    # ìˆœí•¨/ìê·¹ì—†ìŒ
    'ìˆœí•´ìš”': 1.2, 'ìˆœí•˜ê³ ': 1.2, 'ìˆœí•¨': 1.2, 'ë¬´ìê·¹': 1.2,
    # ê°€ì„±ë¹„
    'ê°€ì„±ë¹„': 1.0, 'ê°“ì„±ë¹„': 1.0, 'ì €ë ´': 0.8, 'í•©ë¦¬ì ': 0.8,
    # ì‚¬ìš©ê°
    'ë°œë¦¼ì„±': 0.8, 'ë¶€ë“œëŸ¬': 1.0, 'ì‚°ëœ»': 1.0, 'ê°€ë²¼': 0.8,
    'ì«€ì«€': 0.8, 'ì´‰ì´‰í•¨': 1.0,
    # í–¥
    'í–¥ì¢‹ì•„': 1.0, 'í–¥ì´ì¢‹': 1.0, 'ì€ì€': 0.8,
    # ì¬êµ¬ë§¤/ì¶”ì²œ
    'ì¬êµ¬ë§¤': 1.5, 'ì¬êµ¬': 1.2, 'ë˜ì‚¬': 1.2, 'ì¶”ì²œ': 1.2, 'ê°•ì¶”': 1.5,
    'ì¸ìƒí…œ': 1.5, 'ê¿€í…œ': 1.2, 'ë§Œì¡±': 1.0, 'ë“í…œ': 1.0,
    # í”¼ë¶€ìƒíƒœ
    'í™”ì¥ì˜': 1.0, 'ë°€ì°©': 0.8, 'ì§€ì†ë ¥': 0.8, 'ì»¤ë²„ë ¥': 0.8,
}

# ë¶€ì • í‚¤ì›Œë“œ (ì´ í‚¤ì›Œë“œê°€ ë¶€ì •ì–´ì™€ í•¨ê»˜ ì“°ì´ë©´ ê¸ì •ì´ ë¨)
NEGATIVE_KEYWORDS = {
    # ë¶€ì‘ìš©
    'íŠ¸ëŸ¬ë¸”': 1.2, 'ë¾°ë£¨ì§€': 1.2, 'ì˜¬ë¼': 0.6, 'ë¹¨ê°œ': 0.8,
    'ìê·¹': 1.0, 'ë”°ê°€': 1.0, 'ë”°ë”': 1.0, 'í™”ëˆ': 0.8,
    'ê°€ë ¤': 0.8, 'ê°„ì§€ëŸ¬': 0.8, 'ì•ŒëŸ¬ì§€': 1.0, 'ë‘ë“œëŸ¬ê¸°': 1.0,
    # ì‚¬ìš©ê° ë¶ˆë§Œ
    'ëˆì ': 1.0, 'ëˆì ê±°': 1.0, 'ë¬´ê±°': 0.8, 'ë‹µë‹µ': 0.8,
    'ê¸°ë¦„': 0.6, 'ë²ˆë“¤': 0.8, 'ìœ ë¶„': 0.6,
    'ë°€ë¦¼': 1.0, 'ë°€ë ¤': 1.0, 'ë“¤ëœ¸': 0.8, 'ê°ì§ˆ': 0.6, 'ë­‰ì¹¨': 0.8,
    # íš¨ê³¼ ì—†ìŒ
    'ë³„ë¡œ': 0.8, 'ì• ë§¤': 0.6, 'ëª¨ë¥´ê² ': 0.6, 'íš¨ê³¼ì—†': 1.0,
    'ê¸°ëŒ€ì´í•˜': 1.0, 'ì‹¤ë§': 1.0, 'ì•„ì‰¬': 0.8, 'í›„íšŒ': 1.0,
    # í–¥ ë¶ˆë§Œ (ë¬¸ë§¥ íŒë‹¨ í•„ìš”í•œ ê²ƒì€ CONTEXT_SENSITIVE_KEYWORDSë¡œ ì´ë™)
    'í–¥ê°•í•´': 0.8, 'í–¥ì´ê°•': 0.8, 'ì¸ê³µí–¥': 0.8,
    # ê°€ê²©
    'ë¹„ì‹¸': 0.8, 'ë¹„ìŒˆ': 0.8,
    # ê¸°íƒ€
    'ë¹„ì¶”': 1.2, 'í™˜ë¶ˆ': 1.0, 'êµí™˜': 0.6,
}

# ë°˜ì „ í‚¤ì›Œë“œ (ë¶€ì •ì–´ì™€ í•¨ê»˜ ì“°ì´ë©´ ì˜ë¯¸ê°€ ë°˜ì „ë¨)
REVERSIBLE_KEYWORDS = {
    'ìê·¹', 'ëˆì ', 'ëˆì ê±°', 'íŠ¸ëŸ¬ë¸”', 'ë¾°ë£¨ì§€', 'ë°€ë¦¼', 'ë°€ë ¤',
    'ë“¤ëœ¸', 'ë¬´ê±°', 'ë‹µë‹µ', 'ê¸°ë¦„', 'ë²ˆë“¤', 'ê°ì§ˆ', 'ë­‰ì¹¨',
    'ë”°ê°€', 'ê°€ë ¤', 'í™”ëˆ', 'í¡ìˆ˜ì•ˆ'
}

# ë¬¸ë§¥ì— ë”°ë¼ ê¸ì •/ë¶€ì •ì´ ë‹¬ë¼ì§€ëŠ” í‚¤ì›Œë“œ (ë¬¸ì¥ ì „ì²´ ë¶„ì„)
CONTEXT_SENSITIVE_KEYWORDS = {
    'ëƒ„ìƒˆ': {
        'positive_patterns': [
            r'ëƒ„ìƒˆ.{0,10}ì¢‹', r'ì¢‹ì€.{0,5}ëƒ„ìƒˆ', r'ëƒ„ìƒˆ.{0,10}ê´œì°®',
            r'ëƒ„ìƒˆ.{0,5}(ì—†|ì•ˆ\s*ë‚˜)', r'ëƒ„ìƒˆ.{0,10}ì€ì€',
        ],
        'negative_patterns': [
            r'ëƒ„ìƒˆ.{0,5}(ë‚˜ìš”|ë‚˜ì„œ|ì‹¬í•´|ì´ìƒ|ë³„ë¡œ|ì‹«)',
        ],
        'default': 'neutral'
    },
    'í–¥': {
        'positive_patterns': [
            r'í–¥.{0,10}ì¢‹', r'ì¢‹ì€.{0,5}í–¥', r'í–¥.{0,10}(ì€ì€|ë¶€ë“œ|ìƒì¾Œ|ê´œì°®|ë§ˆìŒì—)',
            r'í–¥ê¸°.{0,5}(ì¢‹|ë‚˜|ë¡­)',
        ],
        'negative_patterns': [
            r'í–¥.{0,5}(ê°•í•´|ì„|ë³„ë¡œ|ê±°ë¶€|ì¸ê³µ|ì‹«)',
        ],
        'default': 'neutral'
    },
    'íŠ¸ëŸ¬ë¸”': {
        # "í‰ì†Œì— íŠ¸ëŸ¬ë¸” ë§ì€ë° ì´ê±° ì“°ê³  ì—†ì–´ì¡Œë‹¤" ê°™ì€ íŒ¨í„´ ì²˜ë¦¬
        'positive_patterns': [
            r'íŠ¸ëŸ¬ë¸”.{0,15}(ì—†|ì•ˆ\s*(ë‚˜|ìƒ|ì˜¬ë¼))',
            r'íŠ¸ëŸ¬ë¸”.{0,5}(ì´|ê°€)?.{0,10}(ì—†|ì•ˆ)',
            r'(ìˆì—ˆëŠ”ë°|ë§ì•˜ëŠ”ë°|ë‚¬ì—ˆëŠ”ë°).{0,20}(íŠ¸ëŸ¬ë¸”|ë¾°ë£¨ì§€).{0,10}(ì—†|ì•ˆ)',
            r'íŠ¸ëŸ¬ë¸”.{0,20}(ì‚¬ë¼|ì¤„|ì¢‹ì•„|ê°œì„ |ì§„ì •)',
            r'(ì“°ê³ |ë°”ë¥´ê³ |ì‚¬ìš©í•˜ê³ ).{0,20}íŠ¸ëŸ¬ë¸”.{0,10}(ì—†|ì•ˆ)',
        ],
        'negative_patterns': [
            r'íŠ¸ëŸ¬ë¸”.{0,5}(ë‚˜|ìƒê¸°|ì˜¬ë¼ì™”|ë‚¬)',
            r'(ì“°ê³ |ë°”ë¥´ê³ |ì‚¬ìš©í•˜ê³ ).{0,10}íŠ¸ëŸ¬ë¸”.{0,5}(ë‚˜|ìƒ)',
        ],
        'default': 'negative'
    },
    'ìê·¹': {
        'positive_patterns': [
            r'ìê·¹.{0,15}(ì—†|ì•ˆ)',
            r'ìê·¹.{0,5}(ì´|ê°€)?.{0,10}(ì—†|ì•ˆ)',
            r'(ë¬´|ì €)ìê·¹',
            r'ìê·¹.{0,10}(ì |ëœ)',
            r'(ì˜ˆë¯¼|ë¯¼ê°).{0,15}(ì¸ë°|í•œë°).{0,15}ìê·¹.{0,10}(ì—†|ì•ˆ|ê´œì°®)',
        ],
        'negative_patterns': [
            r'ìê·¹.{0,5}(ìˆ|ë˜|ëŠê»´|ì‹¬)',
            r'ìê·¹.{0,5}(ì´|ê°€)?.{0,5}(ìˆ|ë˜)',
        ],
        'default': 'negative'
    },
    'ëˆì ': {
        'positive_patterns': [
            r'ëˆì .{0,15}(ì—†|ì•ˆ)',
            r'ëˆì .{0,5}(ì„|ê±°ë¦¼)?.{0,10}(ì—†|ì•ˆ)',
            r'(ìƒê°ë³´ë‹¤|ì˜ì™¸ë¡œ).{0,10}ëˆì .{0,10}(ì—†|ì•ˆ)',
        ],
        'negative_patterns': [
            r'ëˆì .{0,5}(ì—¬|ê±°ë ¤|í•´|í•¨|ìˆ)',
        ],
        'default': 'negative'
    },
}

# ë¬¸ì¥ ë ˆë²¨ ê¸ì • ì „í™˜ íŒ¨í„´ (ê³¼ê±° ë¶€ì • â†’ í˜„ì¬ ê¸ì •)
SENTENCE_REVERSAL_PATTERNS = [
    # "í‰ì†Œì— XXX ìˆëŠ”ë°/ë§ì€ë° ì´ê±° ì“°ê³  ì—†ì–´ì¡Œë‹¤/ì•ˆ ë‚œë‹¤"
    (r'(í‰ì†Œ|ì›ë˜|ì „ì—|ì˜ˆì „).{0,15}(íŠ¸ëŸ¬ë¸”|ë¾°ë£¨ì§€|ìê·¹|ê°ì§ˆ).{0,15}(ìˆ|ë§|ë‚¬|ìƒ).{0,20}(ì´ê±°|ì´\s*ì œí’ˆ|ì‚¬ìš©).{0,20}(ì—†|ì•ˆ|ì‚¬ë¼|ì¤„|ì¢‹ì•„)', 'positive'),
    # "XXXì´ ìˆì—ˆëŠ”ë°/ë§ì•˜ëŠ”ë° ì—†ì–´ì¡Œë‹¤/ì¤„ì—ˆë‹¤"
    (r'(íŠ¸ëŸ¬ë¸”|ë¾°ë£¨ì§€|ìê·¹|ëˆì |ê°ì§ˆ).{0,10}(ì´|ê°€)?\s*(ìˆì—ˆëŠ”ë°|ë§ì•˜ëŠ”ë°|ë‚¬ì—ˆëŠ”ë°|ìƒê²¼ì—ˆëŠ”ë°|ì‹¬í–ˆëŠ”ë°).{0,20}(ì—†|ì•ˆ|ì‚¬ë¼|ì¤„|ì§„ì •)', 'positive'),
    # "ê±±ì •í–ˆëŠ”ë° XXX ì—†ì—ˆë‹¤"
    (r'(ê±±ì •|ì—¼ë ¤|ë¶ˆì•ˆ).{0,15}(íŠ¸ëŸ¬ë¸”|ìê·¹|ëˆì ).{0,15}(ì—†|ì•ˆ|ê´œì°®)', 'positive'),
    # "ë¯¼ê°í•œë° XXX ì—†ë‹¤"
    (r'(ë¯¼ê°|ì˜ˆë¯¼|ì•½í•œ).{0,10}(í”¼ë¶€|í¸)?.{0,15}(íŠ¸ëŸ¬ë¸”|ìê·¹).{0,15}(ì—†|ì•ˆ|ê´œì°®)', 'positive'),
    # "ì“°ê³ /ë°”ë¥´ê³ /ì‚¬ìš©í•˜ê³  ë‚˜ì„œ XXX ì—†ë‹¤/ì¤„ì—ˆë‹¤"
    (r'(ì“°ê³ |ë°”ë¥´ê³ |ì‚¬ìš©í•˜ê³ |ë°œë¼ë³´ë‹ˆ|ì¨ë³´ë‹ˆ).{0,20}(íŠ¸ëŸ¬ë¸”|ë¾°ë£¨ì§€|ìê·¹|ëˆì ).{0,15}(ì—†|ì•ˆ|ì‚¬ë¼|ì¤„)', 'positive'),
    # "XXXì´ í‰ì†Œì— ë§ì€ë° ì´ê±° ì“°ê³  ê·¸ëŸ°ê²Œ ì—†ë‹¤"
    (r'(íŠ¸ëŸ¬ë¸”|ë¾°ë£¨ì§€|ìê·¹).{0,10}(ì´|ê°€)?\s*í‰ì†Œ.{0,10}(ìˆ|ë§).{0,20}(ì´ê±°|ì´\s*ì œí’ˆ|ì“°ê³ ).{0,20}(ê·¸ëŸ°\s*ê²Œ|ê·¸ëŸ°ê±°)?\s*(ì—†|ì•ˆ)', 'positive'),
    # "ì›ë˜ XXX ì˜ ë‚˜ëŠ”/ìƒê¸°ëŠ” í¸ì¸ë° ì•ˆ ë‚¬ë‹¤"
    (r'(ì›ë˜|í‰ì†Œ).{0,10}(íŠ¸ëŸ¬ë¸”|ë¾°ë£¨ì§€|ìê·¹).{0,10}(ì˜|ìì£¼).{0,10}(ë‚˜|ìƒê¸°|ì˜¬ë¼).{0,15}(ì¸ë°|í¸ì¸ë°).{0,15}(ì—†|ì•ˆ)', 'positive'),
    # "XXX ë§ì€ í¸ì¸ë° ê´œì°®ë‹¤/ì¢‹ë‹¤"
    (r'(íŠ¸ëŸ¬ë¸”|ë¾°ë£¨ì§€|ìê·¹|ëˆì ).{0,10}(ë§ì€|ìì£¼|ì‰¬ìš´).{0,10}(í¸|íƒ€ì…).{0,15}(ì¸ë°|ì´ì§€ë§Œ).{0,15}(ê´œì°®|ì¢‹|ì—†|ì•ˆ)', 'positive'),
]


def has_negation_before(text: str, keyword: str, window: int = 8) -> bool:
    """í‚¤ì›Œë“œ ì•ì— ë¶€ì •ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸ (window ê¸€ì ë‚´)"""
    idx = text.find(keyword)
    if idx == -1:
        return False

    # í‚¤ì›Œë“œ ì• window ê¸€ì í™•ì¸
    start = max(0, idx - window)
    before_text = text[start:idx]

    for neg_pattern in NEGATION_PATTERNS:
        if re.search(neg_pattern, before_text):
            return True

    return False


def analyze_context_sensitive_keyword(text: str, keyword: str) -> str:
    """
    ë¬¸ë§¥ì— ë”°ë¼ ê°ì„±ì´ ë‹¬ë¼ì§€ëŠ” í‚¤ì›Œë“œ ë¶„ì„

    Returns:
        'positive', 'negative', or 'neutral'
    """
    if keyword not in CONTEXT_SENSITIVE_KEYWORDS:
        return 'neutral'

    config = CONTEXT_SENSITIVE_KEYWORDS[keyword]

    # ê¸ì • íŒ¨í„´ ì²´í¬
    for pattern in config['positive_patterns']:
        if re.search(pattern, text):
            return 'positive'

    # ë¶€ì • íŒ¨í„´ ì²´í¬
    for pattern in config['negative_patterns']:
        if re.search(pattern, text):
            return 'negative'

    return config['default']


def analyze_sentiment_with_context(text: str) -> Tuple[str, List[str], List[str], float]:
    """
    ë¬¸ë§¥ ê¸°ë°˜ ê°ì„± ë¶„ì„ (ì „ì²´ ë¬¸ì¥ íŒ¨í„´ ìš°ì„ )

    Returns:
        (sentiment, positive_found, negative_found, score)
    """
    text_clean = text.replace('\n', ' ').strip()

    positive_found = []
    negative_found = []
    score = 0.0

    # 0. ë¬¸ì¥ ë ˆë²¨ ê¸ì • ì „í™˜ íŒ¨í„´ ë¨¼ì € ì²´í¬ (ê°€ì¥ ìš°ì„ !)
    # ì˜ˆ: "í‰ì†Œì— íŠ¸ëŸ¬ë¸” ë§ì•˜ëŠ”ë° ì´ê±° ì“°ê³  ì—†ì–´ì¡Œë‹¤" â†’ ì „ì²´ê°€ ê¸ì •
    matched_keywords = set()  # ë¬¸ì¥ íŒ¨í„´ìœ¼ë¡œ ì´ë¯¸ ì²˜ë¦¬ëœ í‚¤ì›Œë“œ
    for pattern, sentiment_type in SENTENCE_REVERSAL_PATTERNS:
        match = re.search(pattern, text_clean)
        if match:
            matched_text = match.group(0)
            if sentiment_type == 'positive':
                positive_found.append(f"ë¬¸ë§¥ì „í™˜ê¸ì •({matched_text[:20]}...)")
                score += 2.0  # ë¬¸ì¥ ë ˆë²¨ íŒ¨í„´ì€ ë” ë†’ì€ ì ìˆ˜
                # í•´ë‹¹ ë¬¸ì¥ì—ì„œ ì–¸ê¸‰ëœ ë¶€ì • í‚¤ì›Œë“œë“¤ì€ ì²˜ë¦¬ ì™„ë£Œë¡œ í‘œì‹œ
                for kw in ['íŠ¸ëŸ¬ë¸”', 'ë¾°ë£¨ì§€', 'ìê·¹', 'ëˆì ', 'ê°ì§ˆ']:
                    if kw in matched_text:
                        matched_keywords.add(kw)

    # 1. ë¬¸ë§¥ ë¯¼ê° í‚¤ì›Œë“œ ì²´í¬ (ëƒ„ìƒˆ, í–¥, íŠ¸ëŸ¬ë¸”, ìê·¹ ë“±)
    # ë‹¨, ë¬¸ì¥ íŒ¨í„´ìœ¼ë¡œ ì´ë¯¸ ì²˜ë¦¬ëœ í‚¤ì›Œë“œëŠ” ì œì™¸
    for keyword in CONTEXT_SENSITIVE_KEYWORDS:
        if keyword in text_clean and keyword not in matched_keywords:
            context_result = analyze_context_sensitive_keyword(text_clean, keyword)
            if context_result == 'positive':
                positive_found.append(f"{keyword}(ê¸ì •)")
                score += 1.0
            elif context_result == 'negative':
                negative_found.append(keyword)
                score -= 1.0
            # neutralì€ ì ìˆ˜ì— ë°˜ì˜ ì•ˆ í•¨

    # 2. ê¸ì • í‚¤ì›Œë“œ ì²´í¬
    for keyword, weight in POSITIVE_KEYWORDS.items():
        if keyword in text_clean:
            # ê¸ì • í‚¤ì›Œë“œ ì•ì— ë¶€ì •ì–´ê°€ ìˆìœ¼ë©´ ë¬´ì‹œ
            if not has_negation_before(text_clean, keyword):
                positive_found.append(keyword)
                score += weight

    # 3. ë¶€ì • í‚¤ì›Œë“œ ì²´í¬ (ë¬¸ë§¥ ê³ ë ¤)
    for keyword, weight in NEGATIVE_KEYWORDS.items():
        # ë¬¸ë§¥ ë¯¼ê° í‚¤ì›Œë“œëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨
        if keyword in CONTEXT_SENSITIVE_KEYWORDS:
            continue

        # ë¬¸ì¥ íŒ¨í„´ìœ¼ë¡œ ì´ë¯¸ ì²˜ë¦¬ëœ í‚¤ì›Œë“œëŠ” ì œì™¸
        if keyword in matched_keywords:
            continue

        if keyword in text_clean:
            # ë°˜ì „ ê°€ëŠ¥í•œ í‚¤ì›Œë“œì¸ ê²½ìš° ë¶€ì •ì–´ ì²´í¬
            if keyword in REVERSIBLE_KEYWORDS:
                if has_negation_before(text_clean, keyword):
                    # "ìê·¹ ì—†ì´" â†’ ê¸ì •
                    positive_found.append(f"{keyword}ì—†ìŒ")
                    score += weight  # ê¸ì • ì ìˆ˜ë¡œ ì¶”ê°€
                else:
                    # "ìê·¹ì´ ìˆì–´" â†’ ë¶€ì •
                    negative_found.append(keyword)
                    score -= weight
            else:
                negative_found.append(keyword)
                score -= weight

    # ê°ì„± íŒì • (ì¤‘ë¦½ì€ ê¸ì •ìœ¼ë¡œ ë¶„ë¥˜)
    if score < -0.5:
        sentiment = 'negative'
    else:
        sentiment = 'positive'  # ì¤‘ë¦½ í¬í•¨

    return sentiment, positive_found, negative_found, score


@dataclass
class ReviewAnalysisResult:
    """ë¦¬ë·° ë¶„ì„ ê²°ê³¼"""
    total_count: int
    positive_count: int
    negative_count: int
    neutral_count: int
    positive_ratio: float
    strengths: List[str]
    weaknesses: List[str]
    top_positive_keywords: List[Tuple[str, int]]
    top_negative_keywords: List[Tuple[str, int]]
    category_scores: Dict[str, float]
    summary: str


@dataclass
class MarketingPointResult:
    """ë§ˆì¼€íŒ… í¬ì¸íŠ¸ ë¶„ì„ ê²°ê³¼"""
    repeated_keywords: List[Tuple[str, int]]  # ë°˜ë³µ í‚¤ì›Œë“œ
    unique_features: List[str]  # íŠ¹ì´ì /ì°¨ë³„ì 
    competitor_mentions: Dict[str, int]  # ê²½ìŸì œí’ˆ ì–¸ê¸‰
    comparison_insights: List[str]  # ë¹„êµ ì¸ì‚¬ì´íŠ¸
    marketing_suggestions: List[str]  # ë§ˆì¼€íŒ… í¬ì¸íŠ¸ ì œì•ˆ


# ê²½ìŸì œí’ˆ/ë¸Œëœë“œ í‚¤ì›Œë“œ (í™•ì¥ ê°€ëŠ¥)
COMPETITOR_BRANDS = {
    # ìŠ¤í‚¨ì¼€ì–´
    'ë©”ë””í', 'ì•„ëˆ„ì•„', 'ë¼ìš´ë“œë©', 'í† ë¦¬ë“ ', 'ìŠ¤í‚¨í‘¸ë“œ', 'ì´ë‹ˆìŠ¤í”„ë¦¬',
    'í´ë¦¬ì˜¤', 'ë¡¬ì•¤', 'ì—ë›°ë“œ', 'ë¯¸ìƒ¤', 'ë”í˜ì´ìŠ¤ìƒµ', 'ë„¤ì´ì²˜ë¦¬í¼ë¸”ë¦­',
    'ì½”ìŠ¤ì•Œì—‘ìŠ¤', 'cosrx', 'ë„˜ë²„ì¦ˆì¸', 'ì•„ì´ì†Œì´', 'ë¹„í”Œë ˆì¸', 'ë‹¬ë°”',
    'ë©”ë…¸í‚¨', 'ê°€ì‰¬', 'êµ¬ë‹¬', 'ë°”ì´ì˜¤ë”ë§ˆ', 'ë¼ë¡œìŠˆí¬ì œ', 'ì•„ë²¤ëŠ',
    # ë©”ì´í¬ì—…
    'í˜ë¦¬í˜ë¼', 'í´ë¦¬ì˜¤', 'íˆ¬ì¿¨í¬ìŠ¤ì¿¨', 'ì›¨ì´í¬ë©”ì´í¬', 'íŒìŠ¤',
    # ì„ ì¼€ì–´
    'ë¼ë¡œìŠˆí¬ì œ', 'ì•„ë²¤ëŠ', 'ìŠ¤í‚¨ì•„ì¿ ì•„', 'ë¹„ì˜¤ë ˆ', 'ì•„ë„·ì‚¬',
}

# ì œí˜•/íŠ¹ì§• í‚¤ì›Œë“œ
FEATURE_KEYWORDS = {
    # ì œí˜•
    'ë¬´ìŠ¤': 'ì œí˜•', 'í¬ë¦¼': 'ì œí˜•', 'ì ¤': 'ì œí˜•', 'ë¡œì…˜': 'ì œí˜•',
    'ì—ì„¼ìŠ¤': 'ì œí˜•', 'ì„¸ëŸ¼': 'ì œí˜•', 'ì˜¤ì¼': 'ì œí˜•', 'ë°¤': 'ì œí˜•',
    'ìŠ¤í‹±': 'ì œí˜•', 'ì¿ ì…˜': 'ì œí˜•', 'íŒŒìš°ë”': 'ì œí˜•', 'ë¯¸ìŠ¤íŠ¸': 'ì œí˜•',
    # ì„±ë¶„
    'íˆì•Œë£¨ë¡ ì‚°': 'ì„±ë¶„', 'ë‚˜ì´ì•„ì‹ ì•„ë§ˆì´ë“œ': 'ì„±ë¶„', 'ë ˆí‹°ë†€': 'ì„±ë¶„',
    'ë¹„íƒ€ë¯¼': 'ì„±ë¶„', 'ì„¸ë¼ë§ˆì´ë“œ': 'ì„±ë¶„', 'íŒí…Œë†€': 'ì„±ë¶„',
    'ì‹œì¹´': 'ì„±ë¶„', 'ì„¼í…”ë¼': 'ì„±ë¶„', 'CICA': 'ì„±ë¶„', 'cica': 'ì„±ë¶„',
    'í”„ë¡œí´ë¦¬ìŠ¤': 'ì„±ë¶„', 'ë…¹ì°¨': 'ì„±ë¶„', 'ë³‘í’€': 'ì„±ë¶„',
    # íŠ¹ì§•
    'ì €ìê·¹': 'íŠ¹ì§•', 'ë¯¼ê°ì„±': 'íŠ¹ì§•', 'ë¹„ê±´': 'íŠ¹ì§•', 'ë¬´í–¥': 'íŠ¹ì§•',
    'ë¬´ì•Œì½œ': 'íŠ¹ì§•', 'ë¬´íŒŒë¼ë²¤': 'íŠ¹ì§•', 'ìì—°ìœ ë˜': 'íŠ¹ì§•',
    'ë”ë¸”ì„¸ëŸ¼': 'íŠ¹ì§•', 'ì•°í”Œ': 'íŠ¹ì§•',
}


def extract_repeated_keywords(reviews: List[Dict], min_count: int = 5) -> List[Tuple[str, int]]:
    """ë¦¬ë·°ì—ì„œ ë°˜ë³µë˜ëŠ” í‚¤ì›Œë“œ ì¶”ì¶œ"""
    all_text = ' '.join([r.get('content', '') for r in reviews])

    # íŠ¹ì§•/ì œí˜•/ì„±ë¶„ í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
    keyword_counts = Counter()

    for keyword in FEATURE_KEYWORDS:
        count = all_text.count(keyword)
        if count >= min_count:
            keyword_counts[keyword] = count

    return keyword_counts.most_common(20)


def find_competitor_mentions(reviews: List[Dict], current_brand: str = '') -> Dict[str, int]:
    """
    ë¦¬ë·°ì—ì„œ ê²½ìŸì œí’ˆ ì–¸ê¸‰ ì°¾ê¸°

    Args:
        reviews: ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
        current_brand: í˜„ì¬ ì œí’ˆ ë¸Œëœë“œ (ì œì™¸ë¨)

    Returns:
        ê²½ìŸ ë¸Œëœë“œë³„ ì–¸ê¸‰ íšŸìˆ˜
    """
    mentions = Counter()
    current_brand_lower = current_brand.lower().strip() if current_brand else ''

    for review in reviews:
        content = review.get('content', '').lower()
        for brand in COMPETITOR_BRANDS:
            brand_lower = brand.lower()
            # í˜„ì¬ ë¸Œëœë“œëŠ” ì œì™¸
            if current_brand_lower and brand_lower in current_brand_lower:
                continue
            if current_brand_lower and current_brand_lower in brand_lower:
                continue
            if brand_lower in content:
                mentions[brand] += 1

    return dict(mentions.most_common(10))


def extract_comparison_sentences(reviews: List[Dict]) -> List[str]:
    """ë¹„êµ ë¬¸ì¥ ì¶”ì¶œ"""
    comparison_patterns = [
        r'.{0,20}(ë³´ë‹¤|ëŒ€ë¹„|ë¹„í•´|ë¹„êµ|ë‹¬ë¦¬|ì°¨ì´|vs|VS).{0,30}',
        r'.{0,20}(ì´ì „|ì „ì—|ì›ë˜|ê¸°ì¡´).{0,20}(ì“°ë˜|ì¼ë˜|ì‚¬ìš©í•˜ë˜).{0,30}',
        r'.{0,20}(ê°ˆì•„íƒ”|ë°”ê¿¨|êµì²´).{0,30}',
    ]

    comparisons = []
    seen = set()

    for review in reviews:
        content = review.get('content', '')
        for pattern in comparison_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                if isinstance(match, tuple):
                    match = ' '.join(match)
                sentence = match.strip()
                if len(sentence) > 10 and sentence not in seen:
                    seen.add(sentence)
                    comparisons.append(sentence)

    return comparisons[:20]


def extract_unique_features(reviews: List[Dict], product_name: str = '') -> List[str]:
    """
    ì œí’ˆì˜ ìœ ë‹ˆí¬í•œ íŠ¹ì§• ì¶”ì¶œ (êµ¬ì²´ì  ë‚´ìš© í•„ìˆ˜)
    - ì œí˜•, ì§ˆê°, ë””ìì¸, ì‚¬ìš©ê° ë“± êµ¬ì²´ì ì¸ ì°¨ë³„ì 
    - ë¹ˆë„ê°€ ë‚®ì•„ë„ ìœ ë‹ˆí¬í•œ ë‚´ìš©ì´ë©´ ì¶”ì¶œ
    """
    unique_mentions = []

    # ìœ ë‹ˆí¬ í¬ì¸íŠ¸ ì¶”ì¶œ íŒ¨í„´ (êµ¬ì²´ì  ë‚´ìš© í¬í•¨)
    # ê° íŒ¨í„´ì€ (regex, category, description) í˜•íƒœ
    unique_patterns = [
        # ì œí˜•/í…ìŠ¤ì²˜ ê´€ë ¨
        (r'(ì œí˜•|í…ìŠ¤ì²˜|ì§ˆê°|ë°œë¦¼ì„±).{0,5}(ì´|ê°€|ë„)?.{0,30}(íŠ¹ì´|ë…íŠ¹|ì‹ ê¸°|ì²˜ìŒ|ìƒˆë¡œ|ë‹¤ë¥´)', 'ì œí˜•'),
        (r'(ì²˜ìŒ|ì²¨).{0,10}(ë³´ëŠ”|ì¨ë³´ëŠ”|ì‚¬ìš©í•´ë³´ëŠ”|ë§Œë‚˜ëŠ”).{0,30}(ì œí˜•|í…ìŠ¤ì²˜|ì§ˆê°|íƒ€ì…|í˜•íƒœ)', 'ì œí˜•'),
        (r'(ì ¤|í¬ë¦¼|ë¡œì…˜|ì˜¤ì¼|ë¬´ìŠ¤|ë°¤|ì—ì„¼ìŠ¤|ì„¸ëŸ¼).{0,5}(íƒ€ì…|í˜•íƒœ|ì œí˜•).{0,20}(íŠ¹ì´|ì‹ ê¸°|ë…íŠ¹|ì²˜ìŒ)', 'ì œí˜•'),
        (r'(ì´ëŸ°|ì´ë ‡ê²Œ).{0,10}(ì œí˜•|í…ìŠ¤ì²˜|ì§ˆê°|ë°œë¦¼).{0,20}(ì²˜ìŒ|ì²¨|ì—†)', 'ì œí˜•'),

        # ë””ìì¸/íŒ¨í‚¤ì§€ ê´€ë ¨
        (r'(ë””ìì¸|íŒ¨í‚¤ì§€|íŒ¨í‚¤ì§•|ìš©ê¸°|ëšœê»‘|íŒí”„).{0,30}(íŠ¹ì´|ë…íŠ¹|ì˜ˆì˜|ì‹ ê¸°|í¸ë¦¬|ì²˜ìŒ)', 'ë””ìì¸'),
        (r'(íŠ¹ì´|ë…íŠ¹|ì‹ ê¸°).{0,10}(ë””ìì¸|íŒ¨í‚¤ì§€|íŒ¨í‚¤ì§•|ìš©ê¸°)', 'ë””ìì¸'),

        # í–¥/ëƒ„ìƒˆ ê´€ë ¨ (ê¸ì •ì  ìœ ë‹ˆí¬)
        (r'(í–¥|ëƒ„ìƒˆ|í–¥ê¸°).{0,5}(ì´|ê°€)?.{0,20}(íŠ¹ì´|ë…íŠ¹|ì‹ ê¸°|ì²˜ìŒ|ìƒˆë¡œ)', 'í–¥'),
        (r'(ì´ëŸ°|ì´ë ‡ê²Œ).{0,5}(í–¥|ëƒ„ìƒˆ).{0,15}(ì²˜ìŒ|ì²¨|ì—†)', 'í–¥'),

        # ì„±ë¶„/íš¨ê³¼ ê´€ë ¨
        (r'(ì„±ë¶„|ì›ë£Œ|ì¶”ì¶œë¬¼).{0,30}(íŠ¹ì´|ë…íŠ¹|ì²˜ìŒ|ìƒˆë¡œ|í¬ê·€)', 'ì„±ë¶„'),
        (r'(íš¨ê³¼|ê¸°ëŠ¥).{0,5}(ê°€|ì´)?.{0,25}(íŠ¹ì´|ë…íŠ¹|ì‹ ê¸°|ë‹¤ë¥´)', 'íš¨ê³¼'),

        # ì‚¬ìš©ê°/ê²½í—˜ ê´€ë ¨
        (r'(ì‚¬ìš©ê°|ëŠë‚Œ|ê°ì´‰).{0,5}(ì´|ê°€)?.{0,25}(íŠ¹ì´|ë…íŠ¹|ì‹ ê¸°|ì²˜ìŒ|ìƒˆë¡œ)', 'ì‚¬ìš©ê°'),
        (r'(ë°”ë¥´|ì‚¬ìš©í•˜).{0,5}(ë©´|ìë§ˆì|ëŠ”\s*ìˆœê°„).{0,30}(íŠ¹ì´|ë…íŠ¹|ì‹ ê¸°)', 'ì‚¬ìš©ê°'),

        # ì¼ë°˜ ìœ ë‹ˆí¬ í‘œí˜„ (êµ¬ì²´ì  ë‚´ìš© í¬í•¨)
        (r'(ë‹¤ë¥¸|íƒ€).{0,5}(ì œí’ˆ|ë¸Œëœë“œ).{0,5}(ì—|ê³¼|ì™€|ì´ë‘)?.{0,5}(ì—†ëŠ”|ë‹¤ë¥¸|ì°¨ë³„).{0,40}', 'ì°¨ë³„ì '),
        (r'(ì²˜ìŒ|ì²¨|ìƒì „).{0,5}(ë³´|ì¨|ì‚¬ìš©|ê²½í—˜|ë§Œë‚˜).{0,40}', 'ì‹ ê·œê²½í—˜'),
        (r'(ì—¬ê¸°|ì´\s*ì œí’ˆ|ì´ê±°).{0,5}(ë§Œ|ì—ì„œë§Œ|ë°–ì—).{0,30}', 'ë…ì '),
        (r'(ìœ ì¼|ìœ ì¼í•˜ê²Œ).{0,40}', 'ìœ ì¼'),
    ]

    for review in reviews:
        content = review.get('content', '')
        if not content:
            continue

        for pattern, category in unique_patterns:
            # íŒ¨í„´ ë§¤ì¹˜ ì°¾ê¸°
            if re.search(pattern, content):
                # ë§¤ì¹­ëœ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë¦¬ë·° ì „ì²´ ë‚´ìš©ì„ ì €ì¥ (ìë¥´ì§€ ì•ŠìŒ)
                unique_mentions.append({
                    'category': category,
                    'text': content,  # ë¦¬ë·° ì „ì²´ ì €ì¥
                    'matched': pattern
                })
                break  # í•œ ë¦¬ë·°ì—ì„œ í•˜ë‚˜ì˜ ì¹´í…Œê³ ë¦¬ë§Œ ì¶”ì¶œ

    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”í•˜ê³  ì¤‘ë³µ ì œê±°
    category_features = {}
    seen_texts = set()

    for mention in unique_mentions:
        cat = mention['category']
        text = mention['text']

        # ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ ì¤‘ë³µ ì œê±°
        text_key = text[:30]  # ì• 30ìë¡œ ì¤‘ë³µ ì²´í¬
        if text_key in seen_texts:
            continue
        seen_texts.add(text_key)

        if cat not in category_features:
            category_features[cat] = []
        category_features[cat].append(text)

    # ê²°ê³¼ ì •ë¦¬ (ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìµœëŒ€ 2ê°œì”©)
    result = []
    priority_categories = ['ì œí˜•', 'ë””ìì¸', 'ì‚¬ìš©ê°', 'í–¥', 'ì„±ë¶„', 'ì°¨ë³„ì ', 'ì‹ ê·œê²½í—˜', 'ìœ ì¼', 'ë…ì ', 'íš¨ê³¼']

    for cat in priority_categories:
        if cat in category_features:
            for text in category_features[cat][:2]:  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 2ê°œ
                result.append(f"[{cat}] {text}")

    return result[:10]  # ìµœëŒ€ 10ê°œ


def generate_marketing_suggestions(
    repeated_keywords: List[Tuple[str, int]],
    competitor_mentions: Dict[str, int],
    unique_features: List[str],
    strengths: List[str]
) -> List[str]:
    """ë§ˆì¼€íŒ… í¬ì¸íŠ¸ ì œì•ˆ ìƒì„± (ìœ ë‹ˆí¬ í¬ì¸íŠ¸ ì¤‘ì‹¬)"""
    suggestions = []

    # 1. ìœ ë‹ˆí¬ í¬ì¸íŠ¸ ìš°ì„  (ê°€ì¥ ì¤‘ìš”!)
    if unique_features:
        suggestions.append("â”â”â” ğŸ¯ ìœ ë‹ˆí¬ í¬ì¸íŠ¸ (ì°¨ë³„í™” ìš”ì†Œ) â”â”â”")
        for feature in unique_features[:5]:
            # [ì¹´í…Œê³ ë¦¬] ë‚´ìš© í˜•íƒœë¡œ ë˜ì–´ ìˆìŒ
            suggestions.append(f"â€¢ {feature}")

    # 2. ê²½ìŸì œí’ˆ ë¹„êµ ê¸°ë°˜
    if competitor_mentions:
        suggestions.append("â”â”â” ğŸ†š ê²½ìŸì œí’ˆ ë¹„êµ â”â”â”")
        for comp, count in list(competitor_mentions.items())[:3]:
            suggestions.append(f"â€¢ '{comp}' ëŒ€ë¹„ ì°¨ë³„ì  ê°•ì¡° ({count}íšŒ ë¹„êµ ì–¸ê¸‰)")

    # 3. í•µì‹¬ ê°•ì  (ë¹ˆì¶œ í‚¤ì›Œë“œ ê¸°ë°˜)
    if repeated_keywords:
        suggestions.append("â”â”â” ğŸ’ª í•µì‹¬ ê°•ì  â”â”â”")
        for keyword, count in repeated_keywords[:3]:
            category = FEATURE_KEYWORDS.get(keyword, '')
            if category:
                suggestions.append(f"â€¢ '{keyword}' ({category}) - {count}íšŒ ì–¸ê¸‰")

    # 4. ë§ˆì¼€íŒ… í™œìš© ì œì•ˆ
    if strengths:
        suggestions.append("â”â”â” ğŸ“¢ ë§ˆì¼€íŒ… í™œìš© ì œì•ˆ â”â”â”")
        for strength in strengths[:3]:
            suggestions.append(f"â€¢ {strength}")

    return suggestions


def analyze_marketing_points(
    reviews: List[Dict],
    product_name: str = '',
    brand: str = ''
) -> MarketingPointResult:
    """
    ë§ˆì¼€íŒ… í¬ì¸íŠ¸ ë¶„ì„

    Args:
        reviews: ë¦¬ë·° ë¦¬ìŠ¤íŠ¸
        product_name: ìƒí’ˆëª…
        brand: ë¸Œëœë“œëª…

    Returns:
        MarketingPointResult
    """
    if not reviews:
        return MarketingPointResult(
            repeated_keywords=[],
            unique_features=[],
            competitor_mentions={},
            comparison_insights=[],
            marketing_suggestions=["ë¶„ì„í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤."]
        )

    # ë¶„ì„ ìˆ˜í–‰
    repeated_keywords = extract_repeated_keywords(reviews)
    competitor_mentions = find_competitor_mentions(reviews, current_brand=brand)
    comparisons = extract_comparison_sentences(reviews)
    unique_features = extract_unique_features(reviews, product_name)

    # ê¸°ë³¸ ë¦¬ë·° ë¶„ì„ (ì¥ì  ì¶”ì¶œìš©)
    analysis = analyze_reviews(reviews)

    # ë§ˆì¼€íŒ… ì œì•ˆ ìƒì„±
    suggestions = generate_marketing_suggestions(
        repeated_keywords,
        competitor_mentions,
        unique_features,
        analysis.strengths
    )

    # ë¹„êµ ì¸ì‚¬ì´íŠ¸ ìƒì„±
    comparison_insights = []
    if competitor_mentions:
        for comp, count in list(competitor_mentions.items())[:3]:
            comparison_insights.append(f"'{comp}'ì™€ {count}íšŒ ë¹„êµë¨")

    return MarketingPointResult(
        repeated_keywords=repeated_keywords,
        unique_features=unique_features,
        competitor_mentions=competitor_mentions,
        comparison_insights=comparison_insights,
        marketing_suggestions=suggestions
    )


# ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ í‚¤ì›Œë“œ
CATEGORY_KEYWORDS = {
    'ë³´ìŠµ': ['ì´‰ì´‰', 'ë³´ìŠµ', 'ìˆ˜ë¶„', 'ê±´ì¡°', 'ë‹¹ê¹€', 'ì´‰ì´‰í•´', 'ì´‰ì´‰í•˜'],
    'í¡ìˆ˜': ['í¡ìˆ˜', 'ìŠ¤ë©°', 'ë¹ ë¥´ê²Œ', 'ê¸ˆë°©', 'ë°”ë¡œ'],
    'ìê·¹': ['ìê·¹', 'ìˆœí•´', 'ìˆœí•˜', 'ë”°ê°€', 'í™”ëˆ', 'íŠ¸ëŸ¬ë¸”', 'ì˜ˆë¯¼', 'ë¯¼ê°'],
    'í–¥': ['í–¥', 'ëƒ„ìƒˆ', 'í–¥ê¸°', 'ì€ì€', 'ê°•í•´', 'ì¸ê³µ'],
    'ë°œë¦¼ì„±': ['ë°œë¦¼', 'ë¶€ë“œëŸ½', 'ì‚°ëœ»', 'ê°€ë³', 'ë¬´ê²', 'ëˆì '],
    'ì§€ì†ë ¥': ['ì§€ì†', 'ì˜¤ë˜', 'ìœ ì§€', 'ë°€ë¦¼', 'ë“¤ëœ¸'],
    'ê°€ì„±ë¹„': ['ê°€ì„±ë¹„', 'ê°€ê²©', 'ë¹„ì‹¸', 'ì €ë ´', 'í•©ë¦¬', 'ì–‘'],
    'íš¨ê³¼': ['íš¨ê³¼', 'ê°œì„ ', 'ì¢‹ì•„ì¡Œ', 'ë³€í™”', 'ë‹¬ë¼'],
}


def analyze_reviews(reviews: List[Dict]) -> ReviewAnalysisResult:
    """
    ë¦¬ë·° ë¦¬ìŠ¤íŠ¸ ë¶„ì„ (ë¬¸ë§¥ ê¸°ë°˜)
    """
    if not reviews:
        return ReviewAnalysisResult(
            total_count=0, positive_count=0, negative_count=0, neutral_count=0,
            positive_ratio=0, strengths=[], weaknesses=[],
            top_positive_keywords=[], top_negative_keywords=[],
            category_scores={}, summary="ë¶„ì„í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤."
        )

    positive_count = 0
    negative_count = 0
    neutral_count = 0

    all_positive_keywords = []
    all_negative_keywords = []
    category_sentiment = {cat: {'pos': 0, 'neg': 0} for cat in CATEGORY_KEYWORDS}

    for review in reviews:
        content = review.get('content', '')
        rating = review.get('rating', 0)

        # ë¬¸ë§¥ ê¸°ë°˜ ê°ì„± ë¶„ì„
        sentiment, pos_found, neg_found, score = analyze_sentiment_with_context(content)

        # í‰ì ì´ ìˆìœ¼ë©´ ì°¸ê³  (í•˜ì§€ë§Œ ë‚´ìš© ë¶„ì„ ìš°ì„ )
        if rating >= 4 and sentiment != 'negative':
            sentiment = 'positive'
        elif rating <= 2 and rating > 0 and sentiment != 'positive':
            sentiment = 'negative'

        if sentiment == 'positive':
            positive_count += 1
        elif sentiment == 'negative':
            negative_count += 1
        else:
            neutral_count += 1

        all_positive_keywords.extend(pos_found)
        all_negative_keywords.extend(neg_found)

        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        for cat, keywords in CATEGORY_KEYWORDS.items():
            for kw in keywords:
                if kw in content:
                    if sentiment == 'positive':
                        category_sentiment[cat]['pos'] += 1
                    elif sentiment == 'negative':
                        category_sentiment[cat]['neg'] += 1

    # í†µê³„
    total = len(reviews)
    positive_ratio = positive_count / total if total > 0 else 0

    top_positive = Counter(all_positive_keywords).most_common(10)
    top_negative = Counter(all_negative_keywords).most_common(10)

    # ì¹´í…Œê³ ë¦¬ë³„ ê¸ì •ë¥ 
    category_scores = {}
    for cat in CATEGORY_KEYWORDS:
        pos = category_sentiment[cat]['pos']
        neg = category_sentiment[cat]['neg']
        total_cat = pos + neg
        if total_cat > 0:
            category_scores[cat] = round(pos / total_cat * 100, 1)

    # ì¥ë‹¨ì  ì¶”ì¶œ
    strengths = _extract_strengths(top_positive, category_scores)
    weaknesses = _extract_weaknesses(top_negative, category_scores)

    # ìš”ì•½
    summary = _generate_summary(total, positive_count, negative_count, strengths, weaknesses, positive_ratio)

    return ReviewAnalysisResult(
        total_count=total,
        positive_count=positive_count,
        negative_count=negative_count,
        neutral_count=neutral_count,
        positive_ratio=round(positive_ratio * 100, 1),
        strengths=strengths,
        weaknesses=weaknesses,
        top_positive_keywords=top_positive,
        top_negative_keywords=top_negative,
        category_scores=category_scores,
        summary=summary
    )


def _extract_strengths(top_positive: List[Tuple[str, int]], category_scores: Dict) -> List[str]:
    """ì¥ì  ë¬¸ì¥ ìƒì„±"""
    strengths = []
    top_keywords = [kw for kw, _ in top_positive[:7]]

    keyword_groups = {
        'ë³´ìŠµ': (['ì´‰ì´‰', 'ë³´ìŠµ', 'ìˆ˜ë¶„', 'ì´‰ì´‰í•´'], "ë³´ìŠµë ¥ì´ ì¢‹ê³  ì´‰ì´‰í•¨ì´ ì˜¤ë˜ ìœ ì§€ë¨"),
        'í¡ìˆ˜': (['í¡ìˆ˜', 'ë¹ ë¥¸í¡ìˆ˜', 'ìŠ¤ë©°', 'í¡ìˆ˜ë¹ ë¦„'], "í¡ìˆ˜ê°€ ë¹ ë¥´ê³  ëˆì ì„ì´ ì—†ìŒ"),
        'ìˆœí•¨': (['ìˆœí•´', 'ìˆœí•˜', 'ìê·¹ì—†ìŒ', 'ë¬´ìê·¹', 'ëˆì ì—†ìŒ'], "ìê·¹ ì—†ì´ ìˆœí•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥"),
        'ë°œë¦¼ì„±': (['ë°œë¦¼', 'ë¶€ë“œëŸ¬', 'ì‚°ëœ»'], "ë°œë¦¼ì„±ì´ ë¶€ë“œëŸ½ê³  ì‚°ëœ»í•¨"),
        'ê°€ì„±ë¹„': (['ê°€ì„±ë¹„', 'ì €ë ´', 'í•©ë¦¬'], "ê°€ê²© ëŒ€ë¹„ ë§Œì¡±ë„ê°€ ë†’ìŒ"),
        'ì¬êµ¬ë§¤': (['ì¬êµ¬ë§¤', 'ì¬êµ¬', 'ë˜ì‚¬', 'ì¶”ì²œ', 'ê°•ì¶”'], "ì¬êµ¬ë§¤ ì˜í–¥ì´ ë†’ì€ ì œí’ˆ"),
    }

    for group_name, (keywords, description) in keyword_groups.items():
        if any(kw in top_keywords for kw in keywords):
            strengths.append(description)

    return strengths[:5]


def _extract_weaknesses(top_negative: List[Tuple[str, int]], category_scores: Dict) -> List[str]:
    """ë‹¨ì  ë¬¸ì¥ ìƒì„±"""
    weaknesses = []
    top_keywords = [kw for kw, _ in top_negative[:7]]

    keyword_groups = {
        'ëˆì ì„': (['ëˆì ', 'ëˆì ê±°', 'ë¬´ê±°'], "ëˆì ì„ì´ ìˆì–´ ë¶ˆí¸í•˜ë‹¤ëŠ” ì˜ê²¬"),
        'ìê·¹': (['íŠ¸ëŸ¬ë¸”', 'ë¾°ë£¨ì§€', 'ìê·¹', 'ë”°ê°€'], "ì¼ë¶€ ì‚¬ìš©ìì—ê²Œ ìê·¹ì´ë‚˜ íŠ¸ëŸ¬ë¸” ë°œìƒ"),
        'í–¥': (['í–¥ê°•', 'ì¸ê³µí–¥', 'ëƒ„ìƒˆ'], "í–¥ì´ ê°•í•˜ê±°ë‚˜ ì¸ê³µì ì´ë¼ëŠ” í‰ê°€"),
        'ê°€ê²©': (['ë¹„ì‹¸', 'ë¹„ìŒˆ'], "ê°€ê²©ì´ ë¹„ì‹¸ë‹¤ëŠ” ì˜ê²¬"),
        'íš¨ê³¼ë¶€ì¡±': (['íš¨ê³¼ì—†', 'ë³„ë¡œ', 'ëª¨ë¥´ê² '], "íš¨ê³¼ë¥¼ ì²´ê°í•˜ê¸° ì–´ë µë‹¤ëŠ” í‰ê°€"),
    }

    for group_name, (keywords, description) in keyword_groups.items():
        if any(kw in top_keywords for kw in keywords):
            weaknesses.append(description)

    return weaknesses[:5]


def _generate_summary(total, positive, negative, strengths, weaknesses, positive_ratio) -> str:
    """ìš”ì•½ë¬¸ ìƒì„±"""
    parts = []

    ratio_pct = positive_ratio * 100

    if ratio_pct >= 80:
        parts.append(f"ì´ {total}ê°œ ë¦¬ë·° ì¤‘ {ratio_pct:.0f}%ê°€ ê¸ì •ì ìœ¼ë¡œ, ë§¤ìš° í˜¸í‰ë°›ëŠ” ì œí’ˆì…ë‹ˆë‹¤.")
    elif ratio_pct >= 60:
        parts.append(f"ì´ {total}ê°œ ë¦¬ë·° ì¤‘ {ratio_pct:.0f}%ê°€ ê¸ì •ì ìœ¼ë¡œ, ëŒ€ì²´ë¡œ ì¢‹ì€ í‰ê°€ë¥¼ ë°›ê³  ìˆìŠµë‹ˆë‹¤.")
    elif ratio_pct >= 40:
        parts.append(f"ì´ {total}ê°œ ë¦¬ë·° ì¤‘ ê¸ì •/ë¶€ì • ë¹„ìœ¨ì´ ë¹„ìŠ·í•˜ì—¬ í˜¸ë¶ˆí˜¸ê°€ ê°ˆë¦¬ëŠ” ì œí’ˆì…ë‹ˆë‹¤.")
    else:
        parts.append(f"ì´ {total}ê°œ ë¦¬ë·° ì¤‘ ë¶€ì •ì  ì˜ê²¬ì´ ë§ì•„ ì£¼ì˜ê°€ í•„ìš”í•œ ì œí’ˆì…ë‹ˆë‹¤.")

    if strengths:
        parts.append(f"ì£¼ìš” ì¥ì : {strengths[0]}")
    if weaknesses:
        parts.append(f"ì£¼ì˜ì‚¬í•­: {weaknesses[0]}")

    return " ".join(parts)


def quick_analyze(reviews: List[Dict]) -> Dict:
    """ê°„í¸ ë¶„ì„"""
    result = analyze_reviews(reviews)
    return {
        'total': result.total_count,
        'positive_ratio': result.positive_ratio,
        'positive_count': result.positive_count,
        'negative_count': result.negative_count,
        'strengths': result.strengths,
        'weaknesses': result.weaknesses,
        'top_positive': result.top_positive_keywords[:5],
        'top_negative': result.top_negative_keywords[:5],
        'category_scores': result.category_scores,
        'summary': result.summary
    }


def quick_marketing_analysis(reviews: List[Dict], product_name: str = '', brand: str = '') -> Dict:
    """ê°„í¸ ë§ˆì¼€íŒ… í¬ì¸íŠ¸ ë¶„ì„"""
    result = analyze_marketing_points(reviews, product_name, brand)
    return {
        'repeated_keywords': result.repeated_keywords[:10],
        'unique_features': result.unique_features,
        'competitor_mentions': result.competitor_mentions,
        'comparison_insights': result.comparison_insights,
        'marketing_suggestions': result.marketing_suggestions
    }


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    sample_reviews = [
        {'content': 'ìê·¹ì´ ì—†ê³  ìˆœí•´ì„œ ì¢‹ì•„ìš”! ì¬êµ¬ë§¤ ì˜ì‚¬ ìˆìŠµë‹ˆë‹¤.', 'rating': 5},
        {'content': 'ëˆì ì„ ì—†ì´ ì´‰ì´‰í•˜ê²Œ í¡ìˆ˜ë¼ìš”', 'rating': 5},
        {'content': 'íŠ¸ëŸ¬ë¸” ì—†ì´ ì˜ ì‚¬ìš©í•˜ê³  ìˆì–´ìš”', 'rating': 4},
        {'content': 'í–¥ì´ ë„ˆë¬´ ê°•í•´ì„œ ë³„ë¡œì˜ˆìš”. ìê·¹ë„ ìˆê³ ...', 'rating': 2},
        {'content': 'ë©”ë””íë³´ë‹¤ ë” ì´‰ì´‰í•œ ê²ƒ ê°™ì•„ìš”', 'rating': 5},
        {'content': 'ê°€ì„±ë¹„ ì¢‹ê³  ìˆœí•´ì„œ ë¯¼ê°í”¼ë¶€ë„ ì‚¬ìš© ê°€ëŠ¥í•´ìš”', 'rating': 4},
        {'content': 'íˆì•Œë£¨ë¡ ì‚° ì„±ë¶„ì´ë¼ ê·¸ëŸ°ì§€ ë³´ìŠµì´ ì¢‹ì•„ìš”', 'rating': 5},
    ]

    print("=== ë¬¸ë§¥ ê¸°ë°˜ ë¦¬ë·° ë¶„ì„ í…ŒìŠ¤íŠ¸ ===\n")

    result = quick_analyze(sample_reviews)
    print(f"ì´ ë¦¬ë·°: {result['total']}ê°œ")
    print(f"ê¸ì • ë¹„ìœ¨: {result['positive_ratio']}%")
    print(f"\nì¥ì :")
    for s in result['strengths']:
        print(f"  - {s}")
    print(f"\në‹¨ì :")
    for w in result['weaknesses']:
        print(f"  - {w}")

    print("\n=== ë§ˆì¼€íŒ… í¬ì¸íŠ¸ ë¶„ì„ í…ŒìŠ¤íŠ¸ ===\n")

    marketing = quick_marketing_analysis(sample_reviews)
    print("ê²½ìŸì œí’ˆ ì–¸ê¸‰:", marketing['competitor_mentions'])
    print("ë°˜ë³µ í‚¤ì›Œë“œ:", marketing['repeated_keywords'][:5])
    print("\në§ˆì¼€íŒ… ì œì•ˆ:")
    for s in marketing['marketing_suggestions']:
        print(f"  - {s}")
